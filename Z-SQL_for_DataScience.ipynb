{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.PySpark Connection part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connection part for Pyspark and importing required packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Pyspark_VS_Pandas\").getOrCreate()\n",
    "conf = spark.sparkContext._conf.setAll([('spark.driver.memory', '4g'), ('spark.executor.memory', '4g'), ('spark.executor.num','6'), ('spark.network.timeout', '1000000')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Reading data into Pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Pyspark dataframe so that we apply SQL scripts for our practice\n",
    "#    1.Read it into Pandas df\n",
    "#    2.convert into pyspark df by defining datatypes of each columns\n",
    "#    [we can use spark.read.format(\"\") option, but it requires additional packages installation so skipped this way]\n",
    "\n",
    "#####################################################################################################\n",
    "#1.STUDENT\n",
    "student_dfpd = pd.read_excel(r'Table_Source\\Student_Placement_Table.xlsx')\n",
    "schema_student = StructType([\\\n",
    "                     StructField(\"ID\",IntegerType(),False),\\\n",
    "                     StructField(\"Name\",StringType(),False),\\\n",
    "                     StructField(\"Gender\",StringType(),False),\\\n",
    "                     StructField(\"DOB\",DateType(),False),\\\n",
    "                     StructField(\"Location\",StringType(),True),\\\n",
    "                     StructField(\"University\",StringType(),False),\\\n",
    "                     StructField(\"Salary\",DoubleType(),False),\\\n",
    "                     StructField(\"Company\",StringType(),False),\\\n",
    "                     StructField(\"Email\",StringType(),False)])\n",
    "\n",
    "student_dfps = spark.createDataFrame(student_dfpd, schema_student)\n",
    "\n",
    "#####################################################################################################\n",
    "#2.UNIVERSITY\n",
    "university_dfpd = pd.read_excel(r'Table_Source\\University_Table.xlsx')\n",
    "schema_university = StructType([\\\n",
    "                     StructField(\"University\",StringType(),False),\\\n",
    "                     StructField(\"MinSalary\",StringType(),False),\\\n",
    "                     StructField(\"PlayGround\",StringType(),False),\\\n",
    "                     StructField(\"Total_Students\",IntegerType(),False)])\n",
    "university_dfps = spark.createDataFrame(university_dfpd, schema_university)\n",
    "\n",
    "#####################################################################################################\n",
    "#3.COMPANY\n",
    "company_dfpd = pd.read_excel(r'Table_Source\\Company_Table.xlsx')\n",
    "schema_company = StructType([\\\n",
    "                     StructField(\"Company\",StringType(),False),\\\n",
    "                     StructField(\"Total_Employes\",IntegerType(),False),\\\n",
    "                     StructField(\"Total_Products\",IntegerType(),False),\\\n",
    "                     StructField(\"Hike_Per_Anum\",IntegerType(),False),\\\n",
    "                     StructField(\"WHF_Office\",StringType(),False)])\n",
    "company_dfps = spark.createDataFrame(company_dfpd, schema_company)\n",
    "#####################################################################################################\n",
    "#3.Year_Month_Day\n",
    "year_month_day_dfpd = pd.read_excel(r'Table_Source\\Year_Month_Day.xlsx')\n",
    "schema_year_month_day = StructType([\\\n",
    "                     StructField(\"Year\",IntegerType(),False),\\\n",
    "                     StructField(\"Month\",StringType(),False),\\\n",
    "                     StructField(\"Day\",IntegerType(),False),\\\n",
    "                     StructField(\"Salary\",IntegerType(),False)])\n",
    "year_month_day_dfps = spark.createDataFrame(year_month_day_dfpd, schema_year_month_day)\n",
    "#####################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.PySpark DataFrame to TempView + Columns datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A. Create pyspark dataframe into Temporary view for applying SQL scripts\n",
    "student_dfps.createOrReplaceTempView(\"Student_Table\")\n",
    "university_dfps.createOrReplaceTempView(\"University_Table\")\n",
    "company_dfps.createOrReplaceTempView(\"Company_Table\")\n",
    "year_month_day_dfps.createOrReplaceTempView(\"Year_Month_Day_Table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Student_Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student_Table Schema:\n",
      "root\n",
      " |-- ID: integer (nullable = false)\n",
      " |-- Name: string (nullable = false)\n",
      " |-- Gender: string (nullable = false)\n",
      " |-- DOB: date (nullable = false)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- University: string (nullable = false)\n",
      " |-- Salary: double (nullable = false)\n",
      " |-- Company: string (nullable = false)\n",
      " |-- Email: string (nullable = false)\n",
      "\n",
      "Total records of Student_Table =  24 \n",
      "\n",
      "Student_Table Data:\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|101| AAA|     M|1994-10-10|Banglore|      IISC|55000.5|Microsoft|  AAA@gmail.com|\n",
      "|102| BBB|     F|1995-09-20|     HYD|      IIIT|76000.2|   Amazon|BBB@hotmail.com|\n",
      "|103| CCC|     M|1992-12-31| Chennai|       NIT|49200.5|   Google|  CCC@gmail.com|\n",
      "|104| DDD|     F|1990-11-22|  Mumbai|       VIT|54980.6|    Apple|DDD@hotmail.com|\n",
      "|105| EEE|     M|1993-05-19| Chennai|       IIT|60200.7|Microsoft|  EEE@gmail.com|\n",
      "|106| FFF|     M|1994-07-23|     HYD|      IIIT|63100.8|Microsoft|  FFF@gmail.com|\n",
      "|107| GGG|     F|1994-10-10|  Mumbai|       VIT|60200.7|   Amazon|GGG@hotmail.com|\n",
      "|108| HHH|     M|1990-10-10|Banglore|       NIT|89200.7|    Apple|  HHH@gmail.com|\n",
      "|109| III|     F|1994-12-21|     HYD|      IIIT|66980.8|   Google|  III@gmail.com|\n",
      "|110| JJJ|     M|1990-11-22| Chennai|       NIT|59250.2|   Amazon|JJJ@hotmail.com|\n",
      "|111| KKK|     M|1994-10-10|Banglore|      IISC|76300.9|Microsoft|  KKK@gmail.com|\n",
      "|112| LLL|     F|1995-09-20|  Mumbai|       NIT|67900.8|    Apple|  LLL@gmail.com|\n",
      "|113| MMM|     F|1994-10-15|     NaN|       VIT|60200.7|   Google|MMM@hotmail.com|\n",
      "|114| NNN|     F|1990-11-29|Banglore|      IIIT|59200.5|   Amazon|  NNN@gmail.com|\n",
      "|115| OOO|     M|1995-09-20|Banglore|      IISC|57120.5|   Google|  OOO@gmail.com|\n",
      "|116| PPP|     F|1994-10-28| Chennai|       IIT|59050.5|    Apple|  PPP@gmail.com|\n",
      "|117| QQQ|     M|1991-02-10|Banglore|      IISC|60200.7|Microsoft|QQQ@hotmail.com|\n",
      "|118| RRR|     F|1993-11-10|  Mumbai|       NIT|52900.5|   Google|  RRR@gmail.com|\n",
      "|119| SSS|     M|1992-10-25|     NaN|       VIT|62900.5|Microsoft|  SSS@gmail.com|\n",
      "|120| TTT|     M|1995-09-29| Chennai|      IIIT|57230.5|    Apple|TTT@hotmail.com|\n",
      "|121| UUU|     F|1990-11-13| Chennai|       NIT|59250.2|   Google|  UUU@gmail.com|\n",
      "|122| VVV|     M|1993-08-19|Banglore|      IISC|57120.5|Microsoft|  VVV@gmail.com|\n",
      "|123| WWW|     F|1994-09-14|  Mumbai|       VIT|59050.5|    Apple|WWW@hotmail.com|\n",
      "|124| XXX|     M|1991-12-19|     HYD|       IIT|60200.7|Microsoft|  XXX@gmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print student table schema\n",
    "print(\"Student_Table Schema:\")\n",
    "student_dfps.printSchema()\n",
    "\n",
    "#print total count of records \n",
    "print(\"Total records of Student_Table = \",student_dfps.count(),\"\\n\\nStudent_Table Data:\")\n",
    "\n",
    "#List all the records in table\n",
    "sql_query = \"SELECT * FROM Student_Table\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. University_Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University_Table Schema:\n",
      "root\n",
      " |-- University: string (nullable = false)\n",
      " |-- MinSalary: string (nullable = false)\n",
      " |-- PlayGround: string (nullable = false)\n",
      " |-- Total_Students: integer (nullable = false)\n",
      "\n",
      "Total records of University_Table =  5 \n",
      "\n",
      "University_Table Data:\n",
      "+----------+---------+----------+--------------+\n",
      "|University|MinSalary|PlayGround|Total_Students|\n",
      "+----------+---------+----------+--------------+\n",
      "|      IISC|      35K|       YES|           250|\n",
      "|      IIIT|      37K|       YES|           300|\n",
      "|       MIT|      32K|       YES|           230|\n",
      "|       IIT|      38K|       YES|           240|\n",
      "|      JNTU|      33K|        NO|           250|\n",
      "+----------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print university table schema\n",
    "print(\"University_Table Schema:\")\n",
    "university_dfps.printSchema()\n",
    "\n",
    "#print total count of records \n",
    "print(\"Total records of University_Table = \",university_dfps.count(),\"\\n\\nUniversity_Table Data:\")\n",
    "\n",
    "#List all the records in table\n",
    "sql_query = \"SELECT * FROM University_Table\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Company_Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company_Table Schema:\n",
      "root\n",
      " |-- Company: string (nullable = false)\n",
      " |-- Total_Employes: integer (nullable = false)\n",
      " |-- Total_Products: integer (nullable = false)\n",
      " |-- Hike_Per_Anum: integer (nullable = false)\n",
      " |-- WHF_Office: string (nullable = false)\n",
      "\n",
      "Total records of Company_Table =  6 \n",
      "\n",
      "Company_Table Data:\n",
      "+---------+--------------+--------------+-------------+----------+\n",
      "|  Company|Total_Employes|Total_Products|Hike_Per_Anum|WHF_Office|\n",
      "+---------+--------------+--------------+-------------+----------+\n",
      "|Microsoft|         25000|            50|           25|       WFH|\n",
      "|      TCS|        450000|            20|           20|    Office|\n",
      "|  Infosys|        350000|            19|           18|    Office|\n",
      "|   Google|         30000|            55|           25|       WFH|\n",
      "|   Amazon|        150000|            25|           22|    Office|\n",
      "|    Apple|        200000|            30|           21|       WFH|\n",
      "+---------+--------------+--------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print company table schema\n",
    "print(\"Company_Table Schema:\")\n",
    "company_dfps.printSchema()\n",
    "\n",
    "#print total count of records \n",
    "print(\"Total records of Company_Table = \",company_dfps.count(),\"\\n\\nCompany_Table Data:\")\n",
    "\n",
    "#List all the records in table\n",
    "sql_query = \"SELECT * FROM Company_Table\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.Year_Month_Day_Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year_Month_Day_Table Schema:\n",
      "root\n",
      " |-- Year: integer (nullable = false)\n",
      " |-- Month: string (nullable = false)\n",
      " |-- Day: integer (nullable = false)\n",
      " |-- Salary: integer (nullable = false)\n",
      "\n",
      "Total records of Company_Table =  12 \n",
      "\n",
      "Company_Table Data:\n",
      "+----+----------+---+------+\n",
      "|Year|     Month|Day|Salary|\n",
      "+----+----------+---+------+\n",
      "|2000| 1.January| 21|    10|\n",
      "|2000| 1.January| 22|    10|\n",
      "|2000| 1.January| 23|    10|\n",
      "|2000|2.February| 21|    10|\n",
      "|2000|2.February| 22|    10|\n",
      "|2000|2.February| 23|    10|\n",
      "|2001| 1.January| 21|    10|\n",
      "|2001| 1.January| 22|    10|\n",
      "|2001| 1.January| 23|    10|\n",
      "|2001|2.February| 21|    10|\n",
      "|2001|2.February| 22|    10|\n",
      "|2001|2.February| 23|    10|\n",
      "+----+----------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print Year_Month_Day_Table  schema\n",
    "print(\"Year_Month_Day_Table Schema:\")\n",
    "year_month_day_dfps.printSchema()\n",
    "\n",
    "#print total count of records \n",
    "print(\"Total records of Company_Table = \",year_month_day_dfps.count(),\"\\n\\nCompany_Table Data:\")\n",
    "\n",
    "#List all the records in table\n",
    "sql_query = \"SELECT * FROM Year_Month_Day_Table\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 😎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.SQL Practice starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @##############################################################@"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4A.Select statement + Alias names + Limit + Count(*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SELECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4A1). Print only ID, NAME, GENDER columns\n",
      "+---+----+------+\n",
      "| ID|NAME|GENDER|\n",
      "+---+----+------+\n",
      "|101| AAA|     M|\n",
      "|102| BBB|     F|\n",
      "|103| CCC|     M|\n",
      "|104| DDD|     F|\n",
      "|105| EEE|     M|\n",
      "+---+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Select statement used to select(Print) data \n",
    "#We can give perticular column names to print, or use * to print all columns\n",
    "# Table name = Student_Table\n",
    "#show(5) for limiting records tobe printed\n",
    "\n",
    "print(\"4A1). Print only ID, NAME, GENDER columns\")\n",
    "sql_query=\"\"\"SELECT ID, NAME, GENDER FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SELECT *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4A2). Print all columns from table\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|101| AAA|     M|1994-10-10|Banglore|      IISC|55000.5|Microsoft|  AAA@gmail.com|\n",
      "|102| BBB|     F|1995-09-20|     HYD|      IIIT|76000.2|   Amazon|BBB@hotmail.com|\n",
      "|103| CCC|     M|1992-12-31| Chennai|       NIT|49200.5|   Google|  CCC@gmail.com|\n",
      "|104| DDD|     F|1990-11-22|  Mumbai|       VIT|54980.6|    Apple|DDD@hotmail.com|\n",
      "|105| EEE|     M|1993-05-19| Chennai|       IIT|60200.7|Microsoft|  EEE@gmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use * for printing all columns data to console, ##show(5) for limiting records tobe printed\n",
    "print(\"4A2). Print all columns from table\")\n",
    "\n",
    "sql_query=\"\"\"SELECT * FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alias names for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4A3). Alias name for ID, Name columns\n",
      "+---------+---------------+\n",
      "|ID_Number|Name_of_Student|\n",
      "+---------+---------------+\n",
      "|      101|            AAA|\n",
      "|      102|            BBB|\n",
      "|      103|            CCC|\n",
      "|      104|            DDD|\n",
      "|      105|            EEE|\n",
      "+---------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Renaming columns with more meaningful names\n",
    "print(\"4A3). Alias name for ID, Name columns\")\n",
    "\n",
    "sql_query=\"\"\"SELECT ID as ID_Number, Name as Name_of_Student FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4A4). Limiting number of records tobe printing on console with Limit by 4\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|101| AAA|     M|1994-10-10|Banglore|      IISC|55000.5|Microsoft|  AAA@gmail.com|\n",
      "|102| BBB|     F|1995-09-20|     HYD|      IIIT|76000.2|   Amazon|BBB@hotmail.com|\n",
      "|103| CCC|     M|1992-12-31| Chennai|       NIT|49200.5|   Google|  CCC@gmail.com|\n",
      "|104| DDD|     F|1990-11-22|  Mumbai|       VIT|54980.6|    Apple|DDD@hotmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Limiting number of records with LIMIT\n",
    "print(\"4A4). Limiting number of records tobe printing on console with Limit by 4\")\n",
    "\n",
    "sql_query=\"\"\"SELECT * FROM Student_Table LIMIT 4\"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count(*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4A5). Print total records in given table\n",
      "+-----------+\n",
      "|Total_Count|\n",
      "+-----------+\n",
      "|         24|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Count(*) function used to return total number of records that are matching given criteria\n",
    "    #if no filter given for count(*), it will print total records in given table\n",
    "\n",
    "print(\"4A5). Print total records in given table\")\n",
    "\n",
    "sql_query=\"\"\"SELECT count(*)as Total_Count FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4A6). Print some sample text using select statement\n",
      "+--------------+\n",
      "|   Column_Name|\n",
      "+--------------+\n",
      "|Hello I am SQL|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Selectng some random text using select statement\n",
    "print(\"4A6). Print some sample text using select statement\")\n",
    "\n",
    "sql_query=\"\"\"SELECT 'Hello I am SQL' as Column_Name \"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4B.Distinct statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4B1). Without Distinct statement, it will lsit all reocrds in that column(s)\n",
      "+--------+\n",
      "|Location|\n",
      "+--------+\n",
      "|Banglore|\n",
      "|     HYD|\n",
      "| Chennai|\n",
      "|  Mumbai|\n",
      "| Chennai|\n",
      "|     HYD|\n",
      "|  Mumbai|\n",
      "|Banglore|\n",
      "|     HYD|\n",
      "| Chennai|\n",
      "|Banglore|\n",
      "|  Mumbai|\n",
      "|     NaN|\n",
      "|Banglore|\n",
      "|Banglore|\n",
      "| Chennai|\n",
      "|Banglore|\n",
      "|  Mumbai|\n",
      "|     NaN|\n",
      "| Chennai|\n",
      "| Chennai|\n",
      "|Banglore|\n",
      "|  Mumbai|\n",
      "|     HYD|\n",
      "+--------+\n",
      "\n",
      "4B2). With Distinct statement, it will lsit only distinct reocrds in that column(s)\n",
      "+--------+\n",
      "|Location|\n",
      "+--------+\n",
      "| Chennai|\n",
      "|  Mumbai|\n",
      "|     NaN|\n",
      "|     HYD|\n",
      "|Banglore|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Distinct statement used for listing only distinct(different) values in column or list of columns\n",
    "\n",
    "print(\"4B1). Without Distinct statement, it will lsit all reocrds in that column(s)\")\n",
    "sql_query=\"SELECT Location FROM Student_Table\"\n",
    "spark.sql(sql_query).show(30)\n",
    "\n",
    "\n",
    "print(\"4B2). With Distinct statement, it will lsit only distinct reocrds in that column(s)\")\n",
    "sql_query=\"SELECT distinct Location FROM Student_Table\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4C.WHERE clause + BETWEEN + LIKE + IN + AND + OR + IS NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WHERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4C1). Print records only from Banglore location\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|101| AAA|     M|1994-10-10|Banglore|      IISC|55000.5|Microsoft|  AAA@gmail.com|\n",
      "|108| HHH|     M|1990-10-10|Banglore|       NIT|89200.7|    Apple|  HHH@gmail.com|\n",
      "|111| KKK|     M|1994-10-10|Banglore|      IISC|76300.9|Microsoft|  KKK@gmail.com|\n",
      "|114| NNN|     F|1990-11-29|Banglore|      IIIT|59200.5|   Amazon|  NNN@gmail.com|\n",
      "|115| OOO|     M|1995-09-20|Banglore|      IISC|57120.5|   Google|  OOO@gmail.com|\n",
      "|117| QQQ|     M|1991-02-10|Banglore|      IISC|60200.7|Microsoft|QQQ@hotmail.com|\n",
      "|122| VVV|     M|1993-08-19|Banglore|      IISC|57120.5|Microsoft|  VVV@gmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Where clause used to filter reocrds based on given condition on columns\n",
    "#Below query will filter records from location Banglore\n",
    "\n",
    "print(\"4C1). Print records only from Banglore location\")\n",
    "sql_query=\"SELECT * FROM Student_Table WHERE Location = 'Banglore'\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WHERE + BETWEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4C2). Print records only ID range from 105 to 109 Inclusive\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|105| EEE|     M|1993-05-19| Chennai|       IIT|60200.7|Microsoft|  EEE@gmail.com|\n",
      "|106| FFF|     M|1994-07-23|     HYD|      IIIT|63100.8|Microsoft|  FFF@gmail.com|\n",
      "|107| GGG|     F|1994-10-10|  Mumbai|       VIT|60200.7|   Amazon|GGG@hotmail.com|\n",
      "|108| HHH|     M|1990-10-10|Banglore|       NIT|89200.7|    Apple|  HHH@gmail.com|\n",
      "|109| III|     F|1994-12-21|     HYD|      IIIT|66980.8|   Google|  III@gmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"4C2). Print records only ID range from 105 to 109 Inclusive\")\n",
    "\n",
    "sql_query=\"\"\"SELECT * FROM Student_Table WHERE ID BETWEEN 105 AND 109\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WHERE + LIKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4C3). Print records only Company value contains soft\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|101| AAA|     M|1994-10-10|Banglore|      IISC|55000.5|Microsoft|  AAA@gmail.com|\n",
      "|105| EEE|     M|1993-05-19| Chennai|       IIT|60200.7|Microsoft|  EEE@gmail.com|\n",
      "|106| FFF|     M|1994-07-23|     HYD|      IIIT|63100.8|Microsoft|  FFF@gmail.com|\n",
      "|111| KKK|     M|1994-10-10|Banglore|      IISC|76300.9|Microsoft|  KKK@gmail.com|\n",
      "|117| QQQ|     M|1991-02-10|Banglore|      IISC|60200.7|Microsoft|QQQ@hotmail.com|\n",
      "|119| SSS|     M|1992-10-25|     NaN|       VIT|62900.5|Microsoft|  SSS@gmail.com|\n",
      "|122| VVV|     M|1993-08-19|Banglore|      IISC|57120.5|Microsoft|  VVV@gmail.com|\n",
      "|124| XXX|     M|1991-12-19|     HYD|       IIT|60200.7|Microsoft|  XXX@gmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"4C3). Print records only Company value contains soft\")\n",
    "\n",
    "sql_query=\"\"\"SELECT * FROM Student_Table WHERE COMPANY LIKE \"%soft%\" \"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WHERE + IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4C4). Print records only Name in given list(AAA, GGG, KKK)\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|101| AAA|     M|1994-10-10|Banglore|      IISC|55000.5|Microsoft|  AAA@gmail.com|\n",
      "|107| GGG|     F|1994-10-10|  Mumbai|       VIT|60200.7|   Amazon|GGG@hotmail.com|\n",
      "|111| KKK|     M|1994-10-10|Banglore|      IISC|76300.9|Microsoft|  KKK@gmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"4C4). Print records only Name in given list(AAA, GGG, KKK)\")\n",
    "\n",
    "sql_query=\"\"\"SELECT * FROM Student_Table WHERE NAME IN ('AAA', 'GGG', 'KKK') \"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WHERE + AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4C5). Print records from Banglore location and Microsoft company\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|101| AAA|     M|1994-10-10|Banglore|      IISC|55000.5|Microsoft|  AAA@gmail.com|\n",
      "|111| KKK|     M|1994-10-10|Banglore|      IISC|76300.9|Microsoft|  KKK@gmail.com|\n",
      "|117| QQQ|     M|1991-02-10|Banglore|      IISC|60200.7|Microsoft|QQQ@hotmail.com|\n",
      "|122| VVV|     M|1993-08-19|Banglore|      IISC|57120.5|Microsoft|  VVV@gmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#And should satisfy all conditions\n",
    "print(\"4C5). Print records from Banglore location and Microsoft company\")\n",
    "\n",
    "sql_query=\"\"\"SELECT * FROM Student_Table WHERE (LOCATION ='Banglore' AND COMPANY ='Microsoft') \"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WHERE + OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4C6). Print records from Banglore location or Microsoft company\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|101| AAA|     M|1994-10-10|Banglore|      IISC|55000.5|Microsoft|  AAA@gmail.com|\n",
      "|105| EEE|     M|1993-05-19| Chennai|       IIT|60200.7|Microsoft|  EEE@gmail.com|\n",
      "|106| FFF|     M|1994-07-23|     HYD|      IIIT|63100.8|Microsoft|  FFF@gmail.com|\n",
      "|108| HHH|     M|1990-10-10|Banglore|       NIT|89200.7|    Apple|  HHH@gmail.com|\n",
      "|111| KKK|     M|1994-10-10|Banglore|      IISC|76300.9|Microsoft|  KKK@gmail.com|\n",
      "|114| NNN|     F|1990-11-29|Banglore|      IIIT|59200.5|   Amazon|  NNN@gmail.com|\n",
      "|115| OOO|     M|1995-09-20|Banglore|      IISC|57120.5|   Google|  OOO@gmail.com|\n",
      "|117| QQQ|     M|1991-02-10|Banglore|      IISC|60200.7|Microsoft|QQQ@hotmail.com|\n",
      "|119| SSS|     M|1992-10-25|     NaN|       VIT|62900.5|Microsoft|  SSS@gmail.com|\n",
      "|122| VVV|     M|1993-08-19|Banglore|      IISC|57120.5|Microsoft|  VVV@gmail.com|\n",
      "|124| XXX|     M|1991-12-19|     HYD|       IIT|60200.7|Microsoft|  XXX@gmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#OR should satisfy any one conditions, Either of the condition will meet the output\n",
    "print(\"4C6). Print records from Banglore location or Microsoft company\")\n",
    "\n",
    "sql_query=\"\"\"SELECT * FROM Student_Table WHERE (LOCATION ='Banglore' OR COMPANY ='Microsoft') \"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WHERE + IS NULL + IS NOT NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4C7). Print records where University is not null, Here all records will be printed because all rows are having Proper values in University column\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|101| AAA|     M|1994-10-10|Banglore|      IISC|55000.5|Microsoft|  AAA@gmail.com|\n",
      "|102| BBB|     F|1995-09-20|     HYD|      IIIT|76000.2|   Amazon|BBB@hotmail.com|\n",
      "|103| CCC|     M|1992-12-31| Chennai|       NIT|49200.5|   Google|  CCC@gmail.com|\n",
      "|104| DDD|     F|1990-11-22|  Mumbai|       VIT|54980.6|    Apple|DDD@hotmail.com|\n",
      "|105| EEE|     M|1993-05-19| Chennai|       IIT|60200.7|Microsoft|  EEE@gmail.com|\n",
      "|106| FFF|     M|1994-07-23|     HYD|      IIIT|63100.8|Microsoft|  FFF@gmail.com|\n",
      "|107| GGG|     F|1994-10-10|  Mumbai|       VIT|60200.7|   Amazon|GGG@hotmail.com|\n",
      "|108| HHH|     M|1990-10-10|Banglore|       NIT|89200.7|    Apple|  HHH@gmail.com|\n",
      "|109| III|     F|1994-12-21|     HYD|      IIIT|66980.8|   Google|  III@gmail.com|\n",
      "|110| JJJ|     M|1990-11-22| Chennai|       NIT|59250.2|   Amazon|JJJ@hotmail.com|\n",
      "|111| KKK|     M|1994-10-10|Banglore|      IISC|76300.9|Microsoft|  KKK@gmail.com|\n",
      "|112| LLL|     F|1995-09-20|  Mumbai|       NIT|67900.8|    Apple|  LLL@gmail.com|\n",
      "|113| MMM|     F|1994-10-15|     NaN|       VIT|60200.7|   Google|MMM@hotmail.com|\n",
      "|114| NNN|     F|1990-11-29|Banglore|      IIIT|59200.5|   Amazon|  NNN@gmail.com|\n",
      "|115| OOO|     M|1995-09-20|Banglore|      IISC|57120.5|   Google|  OOO@gmail.com|\n",
      "|116| PPP|     F|1994-10-28| Chennai|       IIT|59050.5|    Apple|  PPP@gmail.com|\n",
      "|117| QQQ|     M|1991-02-10|Banglore|      IISC|60200.7|Microsoft|QQQ@hotmail.com|\n",
      "|118| RRR|     F|1993-11-10|  Mumbai|       NIT|52900.5|   Google|  RRR@gmail.com|\n",
      "|119| SSS|     M|1992-10-25|     NaN|       VIT|62900.5|Microsoft|  SSS@gmail.com|\n",
      "|120| TTT|     M|1995-09-29| Chennai|      IIIT|57230.5|    Apple|TTT@hotmail.com|\n",
      "|121| UUU|     F|1990-11-13| Chennai|       NIT|59250.2|   Google|  UUU@gmail.com|\n",
      "|122| VVV|     M|1993-08-19|Banglore|      IISC|57120.5|Microsoft|  VVV@gmail.com|\n",
      "|123| WWW|     F|1994-09-14|  Mumbai|       VIT|59050.5|    Apple|WWW@hotmail.com|\n",
      "|124| XXX|     M|1991-12-19|     HYD|       IIT|60200.7|Microsoft|  XXX@gmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Is Null will filter given column having Null values, #Is Not Null will print having proper value\n",
    "# Null is nothing but, missing value in any column(Except Primay key column), it will represent with some meaningful value\n",
    "\n",
    "print(\"4C7). Print records where University is not null, Here all records will be printed because all rows are having Proper values in University column\")\n",
    "\n",
    "sql_query=\"\"\"SELECT * FROM Student_Table WHERE University IS NOT NULL\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4D.Order By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ORDER BY ASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4D1). Sort by Salary Accending order top 5 records\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|103| CCC|     M|1992-12-31| Chennai|       NIT|49200.5|   Google|  CCC@gmail.com|\n",
      "|118| RRR|     F|1993-11-10|  Mumbai|       NIT|52900.5|   Google|  RRR@gmail.com|\n",
      "|104| DDD|     F|1990-11-22|  Mumbai|       VIT|54980.6|    Apple|DDD@hotmail.com|\n",
      "|101| AAA|     M|1994-10-10|Banglore|      IISC|55000.5|Microsoft|  AAA@gmail.com|\n",
      "|115| OOO|     M|1995-09-20|Banglore|      IISC|57120.5|   Google|  OOO@gmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bydefault it is Accending order, for descending order we have to use DESC keyword\n",
    "    #Number: 0 to n bydefault, DESC: n to 0\n",
    "    #Alphabets: A to Z bydefault, DESC: Z to A\n",
    "    \n",
    "print(\"4D1). Sort by Salary Accending order top 5 records\")\n",
    "\n",
    "sql_query=\"\"\"SELECT * FROM Student_Table ORDER BY Salary LIMIT 5\"\"\"\n",
    "spark.sql(sql_query).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ORDER BY DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4D2). Sort by Name Descending order top 5 records\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|124| XXX|     M|1991-12-19|     HYD|       IIT|60200.7|Microsoft|  XXX@gmail.com|\n",
      "|123| WWW|     F|1994-09-14|  Mumbai|       VIT|59050.5|    Apple|WWW@hotmail.com|\n",
      "|122| VVV|     M|1993-08-19|Banglore|      IISC|57120.5|Microsoft|  VVV@gmail.com|\n",
      "|121| UUU|     F|1990-11-13| Chennai|       NIT|59250.2|   Google|  UUU@gmail.com|\n",
      "|120| TTT|     M|1995-09-29| Chennai|      IIIT|57230.5|    Apple|TTT@hotmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"4D2). Sort by Name Descending order top 5 records\")\n",
    "\n",
    "sql_query=\"\"\"SELECT * FROM Student_Table ORDER BY Name DESC LIMIT 5\"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4E. Upper() + Lower() + Length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4E1). Apply Upper(), Lower(), Length() functions to columns\n",
      "+---------+--------------+--------------+---------------+\n",
      "|  COMPANY|upper(COMPANY)|lower(COMPANY)|length(COMPANY)|\n",
      "+---------+--------------+--------------+---------------+\n",
      "|Microsoft|     MICROSOFT|     microsoft|              9|\n",
      "|    Apple|         APPLE|         apple|              5|\n",
      "|   Amazon|        AMAZON|        amazon|              6|\n",
      "|   Google|        GOOGLE|        google|              6|\n",
      "+---------+--------------+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Upper()-->Convert given column data into upper case data\n",
    "#Lower()-->Convert given column data into lower case data\n",
    "#Length()-->It will print total characters in columns data including spaces\n",
    "\n",
    "print(\"4E1). Apply Upper(), Lower(), Length() functions to columns\")\n",
    "\n",
    "sql_query=\"\"\"SELECT DISTINCT COMPANY,UPPER(COMPANY), LOWER(COMPANY), LENGTH(COMPANY) FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4F. Concatination(||) + BooleanExpression + TRIM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4F1). Concatination using || symbol\n",
      "+------------------+\n",
      "|         SelfIntro|\n",
      "+------------------+\n",
      "|I am AAA from IISC|\n",
      "|I am BBB from IIIT|\n",
      "| I am CCC from NIT|\n",
      "| I am DDD from VIT|\n",
      "| I am EEE from IIT|\n",
      "|I am FFF from IIIT|\n",
      "| I am GGG from VIT|\n",
      "| I am HHH from NIT|\n",
      "|I am III from IIIT|\n",
      "| I am JJJ from NIT|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Concatination using ||\n",
    "    #This will help to club mutiple columns and some text into single column\n",
    "\n",
    "print(\"4F1). Concatination using || symbol\")\n",
    "\n",
    "sql_query=\"\"\"SELECT 'I am ' || Name || ' from ' || University as SelfIntro FROM Student_Table LIMIT 10\"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boolean Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4F2). Boolean Expression with some condition\n",
      "+---+----+-------+---------------------+\n",
      "| ID|NAME| SALARY|IsSalaryGraterThan60K|\n",
      "+---+----+-------+---------------------+\n",
      "|101| AAA|55000.5|                false|\n",
      "|102| BBB|76000.2|                 true|\n",
      "|103| CCC|49200.5|                false|\n",
      "|104| DDD|54980.6|                false|\n",
      "|105| EEE|60200.7|                 true|\n",
      "|106| FFF|63100.8|                 true|\n",
      "|107| GGG|60200.7|                 true|\n",
      "|108| HHH|89200.7|                 true|\n",
      "|109| III|66980.8|                 true|\n",
      "|110| JJJ|59250.2|                false|\n",
      "+---+----+-------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Boolean Expression with some condition:\n",
    "    #THis will print True or False values \n",
    "\n",
    "print(\"4F2). Boolean Expression with some condition\")\n",
    "\n",
    "sql_query=\"\"\"SELECT ID, NAME, SALARY, (Salary > 60000) As IsSalaryGraterThan60K FROM Student_Table LIMIT 10\"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4F3). Trim() function used to remove extra spaces in column's data\n",
      "+-------------+---------------+-----------+---------------+\n",
      "|  ExtraSpaces|Len_ExtraSpaces|TrimApplied|Len_TrimApplied|\n",
      "+-------------+---------------+-----------+---------------+\n",
      "|   Google    |             13|     Google|              6|\n",
      "+-------------+---------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Trim() function used to remove extra spaces in column's data\n",
    "\n",
    "print(\"4F3). Trim() function used to remove extra spaces in column's data\")\n",
    "\n",
    "sql_query=\"\"\"SELECT \n",
    "'   Google    ' AS ExtraSpaces, LENGTH('   Google    ') AS Len_ExtraSpaces,\n",
    "TRIM('   Google    ') AS TrimApplied, LENGTH(TRIM('   Google    ')) AS Len_TrimApplied\n",
    "\"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4G.SUBSTRING() + REPLACE() + POSITION() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SUBSTRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4G1).Extract IIIT from IIIT Banglore\n",
      "+-------------+---------------+\n",
      "|   FullColumn|SubstringColumn|\n",
      "+-------------+---------------+\n",
      "|IIIT Banglore|           IIIT|\n",
      "+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SUBSTRING() --> function extracts given range text from column \n",
    "\n",
    "print(\"4G1).Extract IIIT from IIIT Banglore\")\n",
    "\n",
    "sql_query=\"\"\"SELECT 'IIIT Banglore' AS FullColumn, SUBSTRING('IIIT Banglore',1,4) AS SubstringColumn \"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### REPLACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4G2). Replace all IIIT to IIIT-B\n",
      "+---+----+----------+--------+\n",
      "| ID|Name|University|Replaced|\n",
      "+---+----+----------+--------+\n",
      "|101| AAA|      IISC|    IISC|\n",
      "|102| BBB|      IIIT|  IIIT-B|\n",
      "|103| CCC|       NIT|     NIT|\n",
      "|104| DDD|       VIT|     VIT|\n",
      "|105| EEE|       IIT|     IIT|\n",
      "|106| FFF|      IIIT|  IIIT-B|\n",
      "|107| GGG|       VIT|     VIT|\n",
      "|108| HHH|       NIT|     NIT|\n",
      "|109| III|      IIIT|  IIIT-B|\n",
      "|110| JJJ|       NIT|     NIT|\n",
      "+---+----+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#REPLACE() --> function will replace given text with given replaced value\n",
    "\n",
    "print(\"4G2). Replace all IIIT to IIIT-B\")\n",
    "\n",
    "sql_query=\"\"\"SELECT ID, Name, University, REPLACE(UNIVERSITY, 'IIIT', 'IIIT-B')AS Replaced FROM Student_Table LIMIT 10\"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### POSITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4G3).Print @ symbol position in Email column\n",
      "+---+----+---------------+--------------+\n",
      "| ID|Name|          Email|PositionColumn|\n",
      "+---+----+---------------+--------------+\n",
      "|101| AAA|  AAA@gmail.com|             4|\n",
      "|102| BBB|BBB@hotmail.com|             4|\n",
      "|103| CCC|  CCC@gmail.com|             4|\n",
      "|104| DDD|DDD@hotmail.com|             4|\n",
      "|105| EEE|  EEE@gmail.com|             4|\n",
      "|106| FFF|  FFF@gmail.com|             4|\n",
      "|107| GGG|GGG@hotmail.com|             4|\n",
      "|108| HHH|  HHH@gmail.com|             4|\n",
      "|109| III|  III@gmail.com|             4|\n",
      "|110| JJJ|JJJ@hotmail.com|             4|\n",
      "+---+----+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#POSITION() --> Will print the position number of given pattern or character or string\n",
    "\n",
    "print(\"4G3).Print @ symbol position in Email column\")\n",
    "\n",
    "sql_query=\"\"\"SELECT ID, Name, Email, POSITION('@' IN Email) AS PositionColumn FROM Student_Table LIMIT 10\"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4H. Aggregation Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MAX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4H1-a).Print Table Based on Salary Descending order \n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|108| HHH|     M|1990-10-10|Banglore|       NIT|89200.7|    Apple|  HHH@gmail.com|\n",
      "|111| KKK|     M|1994-10-10|Banglore|      IISC|76300.9|Microsoft|  KKK@gmail.com|\n",
      "|102| BBB|     F|1995-09-20|     HYD|      IIIT|76000.2|   Amazon|BBB@hotmail.com|\n",
      "|112| LLL|     F|1995-09-20|  Mumbai|       NIT|67900.8|    Apple|  LLL@gmail.com|\n",
      "|109| III|     F|1994-12-21|     HYD|      IIIT|66980.8|   Google|  III@gmail.com|\n",
      "|106| FFF|     M|1994-07-23|     HYD|      IIIT|63100.8|Microsoft|  FFF@gmail.com|\n",
      "|119| SSS|     M|1992-10-25|     NaN|       VIT|62900.5|Microsoft|  SSS@gmail.com|\n",
      "|117| QQQ|     M|1991-02-10|Banglore|      IISC|60200.7|Microsoft|QQQ@hotmail.com|\n",
      "|113| MMM|     F|1994-10-15|     NaN|       VIT|60200.7|   Google|MMM@hotmail.com|\n",
      "|107| GGG|     F|1994-10-10|  Mumbai|       VIT|60200.7|   Amazon|GGG@hotmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n",
      "4H1-b).Print Maximum value in Salary\n",
      "+----------+\n",
      "|MAX_Salary|\n",
      "+----------+\n",
      "|   89200.7|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Sort table based on DOB Descending order\n",
    "\n",
    "print(\"4H1-a).Print Table Based on Salary Descending order \")\n",
    "sql_query=\"\"\"SELECT * FROM Student_Table ORDER BY Salary DESC LIMIT 10\"\"\"\n",
    "spark.sql(sql_query).show()\n",
    "\n",
    "\n",
    "print(\"4H1-b).Print Maximum value in Salary\")\n",
    "sql_query=\"\"\"SELECT MAX(Salary) AS MAX_Salary FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MIN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4H2-a).Print Table Based on Salary Assending order \n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|103| CCC|     M|1992-12-31| Chennai|       NIT|49200.5|   Google|  CCC@gmail.com|\n",
      "|118| RRR|     F|1993-11-10|  Mumbai|       NIT|52900.5|   Google|  RRR@gmail.com|\n",
      "|104| DDD|     F|1990-11-22|  Mumbai|       VIT|54980.6|    Apple|DDD@hotmail.com|\n",
      "|101| AAA|     M|1994-10-10|Banglore|      IISC|55000.5|Microsoft|  AAA@gmail.com|\n",
      "|115| OOO|     M|1995-09-20|Banglore|      IISC|57120.5|   Google|  OOO@gmail.com|\n",
      "|122| VVV|     M|1993-08-19|Banglore|      IISC|57120.5|Microsoft|  VVV@gmail.com|\n",
      "|120| TTT|     M|1995-09-29| Chennai|      IIIT|57230.5|    Apple|TTT@hotmail.com|\n",
      "|116| PPP|     F|1994-10-28| Chennai|       IIT|59050.5|    Apple|  PPP@gmail.com|\n",
      "|123| WWW|     F|1994-09-14|  Mumbai|       VIT|59050.5|    Apple|WWW@hotmail.com|\n",
      "|114| NNN|     F|1990-11-29|Banglore|      IIIT|59200.5|   Amazon|  NNN@gmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n",
      "4H2-b).Print Minimum value in Salary\n",
      "+----------+\n",
      "|MIN_Salary|\n",
      "+----------+\n",
      "|   49200.5|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Sort table based on DOB Descending order\n",
    "\n",
    "print(\"4H2-a).Print Table Based on Salary Assending order \")\n",
    "sql_query=\"\"\"SELECT * FROM Student_Table ORDER BY Salary LIMIT 10\"\"\"\n",
    "spark.sql(sql_query).show()\n",
    "\n",
    "\n",
    "print(\"4H2-b).Print Minimum value in Salary\")\n",
    "sql_query=\"\"\"SELECT MIN(Salary) AS MIN_Salary FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AVG() + SUM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4H3).AVG(), SUM() functions\n",
      "+-----------------+------------------+\n",
      "|    AverageSalary|         SumSalary|\n",
      "+-----------------+------------------+\n",
      "|61780.98750000001|1482743.7000000002|\n",
      "+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#AVG() for average, SUM() for sum values based on given condition on column\n",
    "print(\"4H3).AVG(), SUM() functions\")\n",
    "sql_query=\"\"\"SELECT AVG(Salary) AS AverageSalary, SUM(Salary) AS SumSalary FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4I. GROUP BY + HAVING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GROUP BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4I1).Print number of Students working in each company \n",
      "+---------+-----------------------+\n",
      "|  Company|TotalStudentsPerCompany|\n",
      "+---------+-----------------------+\n",
      "|   Google|                      6|\n",
      "|Microsoft|                      8|\n",
      "|    Apple|                      6|\n",
      "|   Amazon|                      4|\n",
      "+---------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#GROUP BY is used to group THE ROWS BASED ON SOME VALUE IN COLUMN \n",
    "    #GROUP BY mainly used in Aggregating functions.\n",
    "\n",
    "print(\"4I1).Print number of Students working in each company \")\n",
    "sql_query=\"\"\"SELECT Company, count(*) TotalStudentsPerCompany FROM Student_Table GROUP BY Company\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4I2).Print Total salary of Students based on company. Note:Round function used\n",
      "+---------+-----------------------+\n",
      "|  Company|TotalStudentsPerCompany|\n",
      "+---------+-----------------------+\n",
      "|   Google|               345653.0|\n",
      "|Microsoft|               495025.0|\n",
      "|    Apple|               387414.0|\n",
      "|   Amazon|               254652.0|\n",
      "+---------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"4I2).Print Total salary of Students based on company. Note:Round function used\")\n",
    "sql_query=\"\"\"SELECT Company, ROUND(SUM(Salary)) TotalStudentsPerCompany FROM Student_Table GROUP BY Company\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4I3).Print list of companies which recruites more than 5 students\n",
      "+---------+-----------------------+\n",
      "|  Company|CompanyHaveMorethan5Stu|\n",
      "+---------+-----------------------+\n",
      "|   Google|                      6|\n",
      "|Microsoft|                      8|\n",
      "|    Apple|                      6|\n",
      "+---------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Having: Having cluase is used because where cluase cannot be used in Aggregated function. It acts like a filter\n",
    "print(\"4I3).Print list of companies which recruites more than 5 students\")\n",
    "\n",
    "sql_query=\"\"\"SELECT Company, COUNT(*) AS CompanyHaveMorethan5Stu \n",
    "FROM Student_Table \n",
    "GROUP BY Company \n",
    "HAVING CompanyHaveMorethan5Stu>5\"\"\"\n",
    "\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4J. Sub Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4J1).Print Student details with uniersity having PlayGround. Hint: Only IIT, IIIT, IISC having PlayGround\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|105| EEE|     M|1993-05-19| Chennai|       IIT|60200.7|Microsoft|  EEE@gmail.com|\n",
      "|116| PPP|     F|1994-10-28| Chennai|       IIT|59050.5|    Apple|  PPP@gmail.com|\n",
      "|124| XXX|     M|1991-12-19|     HYD|       IIT|60200.7|Microsoft|  XXX@gmail.com|\n",
      "|102| BBB|     F|1995-09-20|     HYD|      IIIT|76000.2|   Amazon|BBB@hotmail.com|\n",
      "|106| FFF|     M|1994-07-23|     HYD|      IIIT|63100.8|Microsoft|  FFF@gmail.com|\n",
      "|109| III|     F|1994-12-21|     HYD|      IIIT|66980.8|   Google|  III@gmail.com|\n",
      "|114| NNN|     F|1990-11-29|Banglore|      IIIT|59200.5|   Amazon|  NNN@gmail.com|\n",
      "|120| TTT|     M|1995-09-29| Chennai|      IIIT|57230.5|    Apple|TTT@hotmail.com|\n",
      "|101| AAA|     M|1994-10-10|Banglore|      IISC|55000.5|Microsoft|  AAA@gmail.com|\n",
      "|111| KKK|     M|1994-10-10|Banglore|      IISC|76300.9|Microsoft|  KKK@gmail.com|\n",
      "|115| OOO|     M|1995-09-20|Banglore|      IISC|57120.5|   Google|  OOO@gmail.com|\n",
      "|117| QQQ|     M|1991-02-10|Banglore|      IISC|60200.7|Microsoft|QQQ@hotmail.com|\n",
      "|122| VVV|     M|1993-08-19|Banglore|      IISC|57120.5|Microsoft|  VVV@gmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SubQuery can be nested inside where cluase of another SELECT statement\n",
    "\n",
    "print(\"4J1).Print Student details with uniersity having PlayGround. Hint: Only IIT, IIIT, IISC having PlayGround\")\n",
    "sql_query=\"\"\"SELECT * \n",
    "FROM Student_Table \n",
    "WHERE University IN(\n",
    "                    SELECT University \n",
    "                    FROM University_Table \n",
    "                    WHERE PlayGround = 'YES')\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4K. Corelated sub queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4K1).Example for Corelated subqueries\n",
      "+---+----+---------------+--------+----------+\n",
      "| ID|Name|          Email|Location|University|\n",
      "+---+----+---------------+--------+----------+\n",
      "|105| EEE|  EEE@gmail.com| Chennai|       IIT|\n",
      "|116| PPP|  PPP@gmail.com| Chennai|       IIT|\n",
      "|124| XXX|  XXX@gmail.com|     HYD|       IIT|\n",
      "|102| BBB|BBB@hotmail.com|     HYD|      IIIT|\n",
      "|106| FFF|  FFF@gmail.com|     HYD|      IIIT|\n",
      "|109| III|  III@gmail.com|     HYD|      IIIT|\n",
      "|114| NNN|  NNN@gmail.com|Banglore|      IIIT|\n",
      "|120| TTT|TTT@hotmail.com| Chennai|      IIIT|\n",
      "|101| AAA|  AAA@gmail.com|Banglore|      IISC|\n",
      "|111| KKK|  KKK@gmail.com|Banglore|      IISC|\n",
      "|115| OOO|  OOO@gmail.com|Banglore|      IISC|\n",
      "|117| QQQ|QQQ@hotmail.com|Banglore|      IISC|\n",
      "|122| VVV|  VVV@gmail.com|Banglore|      IISC|\n",
      "+---+----+---------------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Corelated subqueries uses values of outer query. \n",
    "#Corelated subquery is executed repeatedly, once for each row evaluated by the outer query.\n",
    "\n",
    "print(\"4K1).Example for Corelated subqueries\")\n",
    "sql_query=\"\"\"SELECT ID, Name, Email, Location, University\n",
    "FROM Student_Table o\n",
    "WHERE EXISTS (\n",
    "                    SELECT University \n",
    "                    FROM University_Table i\n",
    "                    WHERE i.University = o.University )\n",
    "                    \n",
    "                    \"\"\"\n",
    "spark.sql(sql_query).show(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4L. Case statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4L). Case Statement\n",
      "+---+----+----------+------------------+\n",
      "| ID|Name|University|     TypeOfCollege|\n",
      "+---+----+----------+------------------+\n",
      "|101| AAA|      IISC|      IISC Student|\n",
      "|102| BBB|      IIIT|      IIIT Student|\n",
      "|103| CCC|       NIT|Remaining Colleges|\n",
      "|104| DDD|       VIT|Remaining Colleges|\n",
      "|105| EEE|       IIT|       IIT Student|\n",
      "|106| FFF|      IIIT|      IIIT Student|\n",
      "|107| GGG|       VIT|Remaining Colleges|\n",
      "|108| HHH|       NIT|Remaining Colleges|\n",
      "|109| III|      IIIT|      IIIT Student|\n",
      "|110| JJJ|       NIT|Remaining Colleges|\n",
      "+---+----+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Case statement used to create new columns with some conditions. \n",
    "print(\"4L). Case Statement\")\n",
    "sql_query=\"\"\"SELECT ID, Name, University, \n",
    "CASE \n",
    "    WHEN University = 'IIT' THEN 'IIT Student'\n",
    "    WHEN University = 'IIIT' THEN 'IIIT Student'\n",
    "    WHEN University = 'IISC' THEN 'IISC Student'\n",
    "    ELSE 'Remaining Colleges' \n",
    "END TypeOfCollege  FROM Student_Table LIMIT 10\"\"\"\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4M. Joins (INNER, LEFT, RIGHT, OUTER, CROSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inner Joins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4M1).Inner Join:\n",
      "List Distinct Universities from Student_Table\n",
      "+----------+\n",
      "|University|\n",
      "+----------+\n",
      "|       NIT|\n",
      "|       IIT|\n",
      "|      IIIT|\n",
      "|      IISC|\n",
      "|       VIT|\n",
      "+----------+\n",
      "\n",
      "List Distinct Universities from University_Table\n",
      "+----------+\n",
      "|University|\n",
      "+----------+\n",
      "|       IIT|\n",
      "|      IIIT|\n",
      "|      IISC|\n",
      "|       MIT|\n",
      "|      JNTU|\n",
      "+----------+\n",
      "\n",
      "List matching Universities from both tables (Student_Table,University_Table)\n",
      "+----------+\n",
      "|University|\n",
      "+----------+\n",
      "|       IIT|\n",
      "|      IIIT|\n",
      "|      IISC|\n",
      "+----------+\n",
      "\n",
      "Example Inner join Query\n",
      "+---+----+----------+----------+--------------+\n",
      "| ID|Name|University|PlayGround|Total_Students|\n",
      "+---+----+----------+----------+--------------+\n",
      "|105| EEE|       IIT|       YES|           240|\n",
      "|116| PPP|       IIT|       YES|           240|\n",
      "|124| XXX|       IIT|       YES|           240|\n",
      "|102| BBB|      IIIT|       YES|           300|\n",
      "|106| FFF|      IIIT|       YES|           300|\n",
      "|109| III|      IIIT|       YES|           300|\n",
      "|114| NNN|      IIIT|       YES|           300|\n",
      "|120| TTT|      IIIT|       YES|           300|\n",
      "|101| AAA|      IISC|       YES|           250|\n",
      "|111| KKK|      IISC|       YES|           250|\n",
      "|115| OOO|      IISC|       YES|           250|\n",
      "|117| QQQ|      IISC|       YES|           250|\n",
      "|122| VVV|      IISC|       YES|           250|\n",
      "+---+----+----------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Joins used for combining columns from multiple tables based on common columns in multiple tables.\n",
    "#Inner--> This join will give results based on matching values in both tabels.\n",
    "\n",
    "print(\"4M1).Inner Join:\\nList Distinct Universities from Student_Table\")\n",
    "sql_query=\"\"\"SELECT DISTINCT University FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show()\n",
    "\n",
    "print(\"List Distinct Universities from University_Table\")\n",
    "sql_query=\"\"\"SELECT DISTINCT University FROM University_Table\"\"\"\n",
    "spark.sql(sql_query).show()\n",
    "\n",
    "print(\"List matching Universities from both tables (Student_Table,University_Table)\")\n",
    "sql_query=\"\"\"SELECT DISTINCT A.University \n",
    "FROM Student_Table A \n",
    "INNER JOIN University_Table B\n",
    "ON A.University = B.University\"\"\"\n",
    "spark.sql(sql_query).show()\n",
    "\n",
    "\n",
    "print(\"Example Inner join Query\")\n",
    "sql_query=\"\"\"SELECT A.ID, A.Name, A.University, B.PlayGround, B.Total_Students \n",
    "FROM Student_Table A \n",
    "INNER JOIN University_Table B\n",
    "ON A.University = B.University\"\"\"\n",
    "spark.sql(sql_query).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Left Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4M2). Example for Left Join Query\n",
      "+---+----+----------+---------+-------+----------+--------------+\n",
      "| ID|Name|University|  Company| Salary|PlayGround|Total_Students|\n",
      "+---+----+----------+---------+-------+----------+--------------+\n",
      "|103| CCC|       NIT|   Google|49200.5|      null|          null|\n",
      "|108| HHH|       NIT|    Apple|89200.7|      null|          null|\n",
      "|110| JJJ|       NIT|   Amazon|59250.2|      null|          null|\n",
      "|112| LLL|       NIT|    Apple|67900.8|      null|          null|\n",
      "|118| RRR|       NIT|   Google|52900.5|      null|          null|\n",
      "|121| UUU|       NIT|   Google|59250.2|      null|          null|\n",
      "|105| EEE|       IIT|Microsoft|60200.7|       YES|           240|\n",
      "|116| PPP|       IIT|    Apple|59050.5|       YES|           240|\n",
      "|124| XXX|       IIT|Microsoft|60200.7|       YES|           240|\n",
      "|102| BBB|      IIIT|   Amazon|76000.2|       YES|           300|\n",
      "|106| FFF|      IIIT|Microsoft|63100.8|       YES|           300|\n",
      "|109| III|      IIIT|   Google|66980.8|       YES|           300|\n",
      "|114| NNN|      IIIT|   Amazon|59200.5|       YES|           300|\n",
      "|120| TTT|      IIIT|    Apple|57230.5|       YES|           300|\n",
      "|101| AAA|      IISC|Microsoft|55000.5|       YES|           250|\n",
      "|111| KKK|      IISC|Microsoft|76300.9|       YES|           250|\n",
      "|115| OOO|      IISC|   Google|57120.5|       YES|           250|\n",
      "|117| QQQ|      IISC|Microsoft|60200.7|       YES|           250|\n",
      "|122| VVV|      IISC|Microsoft|57120.5|       YES|           250|\n",
      "|104| DDD|       VIT|    Apple|54980.6|      null|          null|\n",
      "|107| GGG|       VIT|   Amazon|60200.7|      null|          null|\n",
      "|113| MMM|       VIT|   Google|60200.7|      null|          null|\n",
      "|119| SSS|       VIT|Microsoft|62900.5|      null|          null|\n",
      "|123| WWW|       VIT|    Apple|59050.5|      null|          null|\n",
      "+---+----+----------+---------+-------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Left Join used for printing all records from Left table(Table-1) and matching records from right table(Table-2)\n",
    "#for non matching records in right table(Table-2) willbe shown as Null\n",
    "\n",
    "print(\"4M2). Example for Left Join Query\")\n",
    "sql_query=\"\"\"SELECT A.ID, A.Name, A.University, A.Company, A.Salary, B.PlayGround, B.Total_Students \n",
    "FROM Student_Table A \n",
    "LEFT JOIN University_Table B\n",
    "ON A.University = B.University\"\"\"\n",
    "spark.sql(sql_query).show(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Right Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4M3). Example for RIGHT Join Query\n",
      "+----+----+----------+---------+-------+----------+--------------+\n",
      "|  ID|Name|University|  Company| Salary|PlayGround|Total_Students|\n",
      "+----+----+----------+---------+-------+----------+--------------+\n",
      "| 105| EEE|       IIT|Microsoft|60200.7|       YES|           240|\n",
      "| 116| PPP|       IIT|    Apple|59050.5|       YES|           240|\n",
      "| 124| XXX|       IIT|Microsoft|60200.7|       YES|           240|\n",
      "| 102| BBB|      IIIT|   Amazon|76000.2|       YES|           300|\n",
      "| 106| FFF|      IIIT|Microsoft|63100.8|       YES|           300|\n",
      "| 109| III|      IIIT|   Google|66980.8|       YES|           300|\n",
      "| 114| NNN|      IIIT|   Amazon|59200.5|       YES|           300|\n",
      "| 120| TTT|      IIIT|    Apple|57230.5|       YES|           300|\n",
      "| 101| AAA|      IISC|Microsoft|55000.5|       YES|           250|\n",
      "| 111| KKK|      IISC|Microsoft|76300.9|       YES|           250|\n",
      "| 115| OOO|      IISC|   Google|57120.5|       YES|           250|\n",
      "| 117| QQQ|      IISC|Microsoft|60200.7|       YES|           250|\n",
      "| 122| VVV|      IISC|Microsoft|57120.5|       YES|           250|\n",
      "|null|null|      null|     null|   null|       YES|           230|\n",
      "|null|null|      null|     null|   null|        NO|           250|\n",
      "+----+----+----------+---------+-------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Right Join used for printing all records from Right table(Table-2) and matching records from left table(Table-1)\n",
    "#for non matching records in left table(Table-1) willbe shown as Null\n",
    "\n",
    "print(\"4M3). Example for RIGHT Join Query\")\n",
    "sql_query=\"\"\"SELECT A.ID, A.Name, A.University, A.Company, A.Salary, B.PlayGround, B.Total_Students \n",
    "FROM Student_Table A \n",
    "RIGHT JOIN University_Table B\n",
    "ON A.University = B.University\"\"\"\n",
    "spark.sql(sql_query).show(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full Outer Join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4M4). Example for FULL OUTER Join Query\n",
      "+----+----+----------+---------+-------+----------+--------------+\n",
      "|  ID|Name|University|  Company| Salary|PlayGround|Total_Students|\n",
      "+----+----+----------+---------+-------+----------+--------------+\n",
      "|null|null|      null|     null|   null|       YES|           230|\n",
      "|null|null|      null|     null|   null|        NO|           250|\n",
      "| 101| AAA|      IISC|Microsoft|55000.5|       YES|           250|\n",
      "| 102| BBB|      IIIT|   Amazon|76000.2|       YES|           300|\n",
      "| 103| CCC|       NIT|   Google|49200.5|      null|          null|\n",
      "| 104| DDD|       VIT|    Apple|54980.6|      null|          null|\n",
      "| 105| EEE|       IIT|Microsoft|60200.7|       YES|           240|\n",
      "| 106| FFF|      IIIT|Microsoft|63100.8|       YES|           300|\n",
      "| 107| GGG|       VIT|   Amazon|60200.7|      null|          null|\n",
      "| 108| HHH|       NIT|    Apple|89200.7|      null|          null|\n",
      "| 109| III|      IIIT|   Google|66980.8|       YES|           300|\n",
      "| 110| JJJ|       NIT|   Amazon|59250.2|      null|          null|\n",
      "| 111| KKK|      IISC|Microsoft|76300.9|       YES|           250|\n",
      "| 112| LLL|       NIT|    Apple|67900.8|      null|          null|\n",
      "| 113| MMM|       VIT|   Google|60200.7|      null|          null|\n",
      "| 114| NNN|      IIIT|   Amazon|59200.5|       YES|           300|\n",
      "| 115| OOO|      IISC|   Google|57120.5|       YES|           250|\n",
      "| 116| PPP|       IIT|    Apple|59050.5|       YES|           240|\n",
      "| 117| QQQ|      IISC|Microsoft|60200.7|       YES|           250|\n",
      "| 118| RRR|       NIT|   Google|52900.5|      null|          null|\n",
      "| 119| SSS|       VIT|Microsoft|62900.5|      null|          null|\n",
      "| 120| TTT|      IIIT|    Apple|57230.5|       YES|           300|\n",
      "| 121| UUU|       NIT|   Google|59250.2|      null|          null|\n",
      "| 122| VVV|      IISC|Microsoft|57120.5|       YES|           250|\n",
      "| 123| WWW|       VIT|    Apple|59050.5|      null|          null|\n",
      "| 124| XXX|       IIT|Microsoft|60200.7|       YES|           240|\n",
      "+----+----+----------+---------+-------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Full Outer Join returns all the records in left join and all records in right join.\n",
    "\n",
    "print(\"4M4). Example for FULL OUTER Join Query\")\n",
    "sql_query=\"\"\"SELECT A.ID, A.Name, A.University, A.Company, A.Salary, B.PlayGround, B.Total_Students \n",
    "FROM Student_Table A \n",
    "FULL OUTER JOIN University_Table B\n",
    "ON A.University = B.University \n",
    "ORDER BY ID\"\"\"\n",
    "spark.sql(sql_query).show(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4M5). Example for Cross Join Query\n",
      "\n",
      "Count of Student_Table =  24\n",
      "\n",
      "Count of University_Table =  5\n",
      "\n",
      "Count(Student_Table) X Count(University_Table) =  120\n",
      "+---+----+----------+----------+---------+-------+----------+--------------+\n",
      "| ID|Name|University|University|  Company| Salary|PlayGround|Total_Students|\n",
      "+---+----+----------+----------+---------+-------+----------+--------------+\n",
      "|102| BBB|      IIIT|      IIIT|   Amazon|76000.2|       YES|           300|\n",
      "|102| BBB|      IIIT|       MIT|   Amazon|76000.2|       YES|           230|\n",
      "|102| BBB|      IIIT|      JNTU|   Amazon|76000.2|        NO|           250|\n",
      "|102| BBB|      IIIT|      IISC|   Amazon|76000.2|       YES|           250|\n",
      "|102| BBB|      IIIT|       IIT|   Amazon|76000.2|       YES|           240|\n",
      "|106| FFF|      IIIT|       MIT|Microsoft|63100.8|       YES|           230|\n",
      "|106| FFF|      IIIT|       IIT|Microsoft|63100.8|       YES|           240|\n",
      "|106| FFF|      IIIT|      JNTU|Microsoft|63100.8|        NO|           250|\n",
      "|106| FFF|      IIIT|      IISC|Microsoft|63100.8|       YES|           250|\n",
      "|106| FFF|      IIIT|      IIIT|Microsoft|63100.8|       YES|           300|\n",
      "|109| III|      IIIT|       MIT|   Google|66980.8|       YES|           230|\n",
      "|109| III|      IIIT|      IIIT|   Google|66980.8|       YES|           300|\n",
      "|109| III|      IIIT|      JNTU|   Google|66980.8|        NO|           250|\n",
      "|109| III|      IIIT|      IISC|   Google|66980.8|       YES|           250|\n",
      "|109| III|      IIIT|       IIT|   Google|66980.8|       YES|           240|\n",
      "|114| NNN|      IIIT|      IISC|   Amazon|59200.5|       YES|           250|\n",
      "|114| NNN|      IIIT|       MIT|   Amazon|59200.5|       YES|           230|\n",
      "|114| NNN|      IIIT|      IIIT|   Amazon|59200.5|       YES|           300|\n",
      "|114| NNN|      IIIT|      JNTU|   Amazon|59200.5|        NO|           250|\n",
      "|114| NNN|      IIIT|       IIT|   Amazon|59200.5|       YES|           240|\n",
      "|120| TTT|      IIIT|      IISC|    Apple|57230.5|       YES|           250|\n",
      "|120| TTT|      IIIT|      JNTU|    Apple|57230.5|        NO|           250|\n",
      "|120| TTT|      IIIT|       IIT|    Apple|57230.5|       YES|           240|\n",
      "|120| TTT|      IIIT|      IIIT|    Apple|57230.5|       YES|           300|\n",
      "|120| TTT|      IIIT|       MIT|    Apple|57230.5|       YES|           230|\n",
      "|101| AAA|      IISC|       MIT|Microsoft|55000.5|       YES|           230|\n",
      "|101| AAA|      IISC|       IIT|Microsoft|55000.5|       YES|           240|\n",
      "|101| AAA|      IISC|      JNTU|Microsoft|55000.5|        NO|           250|\n",
      "|101| AAA|      IISC|      IIIT|Microsoft|55000.5|       YES|           300|\n",
      "|101| AAA|      IISC|      IISC|Microsoft|55000.5|       YES|           250|\n",
      "|111| KKK|      IISC|       IIT|Microsoft|76300.9|       YES|           240|\n",
      "|111| KKK|      IISC|      IISC|Microsoft|76300.9|       YES|           250|\n",
      "|111| KKK|      IISC|       MIT|Microsoft|76300.9|       YES|           230|\n",
      "|111| KKK|      IISC|      IIIT|Microsoft|76300.9|       YES|           300|\n",
      "|111| KKK|      IISC|      JNTU|Microsoft|76300.9|        NO|           250|\n",
      "|115| OOO|      IISC|       IIT|   Google|57120.5|       YES|           240|\n",
      "|115| OOO|      IISC|      IISC|   Google|57120.5|       YES|           250|\n",
      "|115| OOO|      IISC|       MIT|   Google|57120.5|       YES|           230|\n",
      "|115| OOO|      IISC|      IIIT|   Google|57120.5|       YES|           300|\n",
      "|115| OOO|      IISC|      JNTU|   Google|57120.5|        NO|           250|\n",
      "|117| QQQ|      IISC|      IISC|Microsoft|60200.7|       YES|           250|\n",
      "|117| QQQ|      IISC|       MIT|Microsoft|60200.7|       YES|           230|\n",
      "|117| QQQ|      IISC|      IIIT|Microsoft|60200.7|       YES|           300|\n",
      "|117| QQQ|      IISC|       IIT|Microsoft|60200.7|       YES|           240|\n",
      "|117| QQQ|      IISC|      JNTU|Microsoft|60200.7|        NO|           250|\n",
      "|122| VVV|      IISC|       IIT|Microsoft|57120.5|       YES|           240|\n",
      "|122| VVV|      IISC|       MIT|Microsoft|57120.5|       YES|           230|\n",
      "|122| VVV|      IISC|      IISC|Microsoft|57120.5|       YES|           250|\n",
      "|122| VVV|      IISC|      JNTU|Microsoft|57120.5|        NO|           250|\n",
      "|122| VVV|      IISC|      IIIT|Microsoft|57120.5|       YES|           300|\n",
      "|105| EEE|       IIT|       IIT|Microsoft|60200.7|       YES|           240|\n",
      "|105| EEE|       IIT|      IIIT|Microsoft|60200.7|       YES|           300|\n",
      "|105| EEE|       IIT|      IISC|Microsoft|60200.7|       YES|           250|\n",
      "|105| EEE|       IIT|       MIT|Microsoft|60200.7|       YES|           230|\n",
      "|105| EEE|       IIT|      JNTU|Microsoft|60200.7|        NO|           250|\n",
      "|116| PPP|       IIT|       MIT|    Apple|59050.5|       YES|           230|\n",
      "|116| PPP|       IIT|       IIT|    Apple|59050.5|       YES|           240|\n",
      "|116| PPP|       IIT|      IISC|    Apple|59050.5|       YES|           250|\n",
      "|116| PPP|       IIT|      IIIT|    Apple|59050.5|       YES|           300|\n",
      "|116| PPP|       IIT|      JNTU|    Apple|59050.5|        NO|           250|\n",
      "|124| XXX|       IIT|      IISC|Microsoft|60200.7|       YES|           250|\n",
      "|124| XXX|       IIT|      IIIT|Microsoft|60200.7|       YES|           300|\n",
      "|124| XXX|       IIT|       IIT|Microsoft|60200.7|       YES|           240|\n",
      "|124| XXX|       IIT|      JNTU|Microsoft|60200.7|        NO|           250|\n",
      "|124| XXX|       IIT|       MIT|Microsoft|60200.7|       YES|           230|\n",
      "|103| CCC|       NIT|       MIT|   Google|49200.5|       YES|           230|\n",
      "|103| CCC|       NIT|      IISC|   Google|49200.5|       YES|           250|\n",
      "|103| CCC|       NIT|       IIT|   Google|49200.5|       YES|           240|\n",
      "|103| CCC|       NIT|      IIIT|   Google|49200.5|       YES|           300|\n",
      "|103| CCC|       NIT|      JNTU|   Google|49200.5|        NO|           250|\n",
      "|108| HHH|       NIT|       MIT|    Apple|89200.7|       YES|           230|\n",
      "|108| HHH|       NIT|      IIIT|    Apple|89200.7|       YES|           300|\n",
      "|108| HHH|       NIT|       IIT|    Apple|89200.7|       YES|           240|\n",
      "|108| HHH|       NIT|      JNTU|    Apple|89200.7|        NO|           250|\n",
      "|108| HHH|       NIT|      IISC|    Apple|89200.7|       YES|           250|\n",
      "|110| JJJ|       NIT|       IIT|   Amazon|59250.2|       YES|           240|\n",
      "|110| JJJ|       NIT|       MIT|   Amazon|59250.2|       YES|           230|\n",
      "|110| JJJ|       NIT|      IIIT|   Amazon|59250.2|       YES|           300|\n",
      "|110| JJJ|       NIT|      IISC|   Amazon|59250.2|       YES|           250|\n",
      "|110| JJJ|       NIT|      JNTU|   Amazon|59250.2|        NO|           250|\n",
      "|112| LLL|       NIT|       MIT|    Apple|67900.8|       YES|           230|\n",
      "|112| LLL|       NIT|      IIIT|    Apple|67900.8|       YES|           300|\n",
      "|112| LLL|       NIT|      IISC|    Apple|67900.8|       YES|           250|\n",
      "|112| LLL|       NIT|       IIT|    Apple|67900.8|       YES|           240|\n",
      "|112| LLL|       NIT|      JNTU|    Apple|67900.8|        NO|           250|\n",
      "|118| RRR|       NIT|       MIT|   Google|52900.5|       YES|           230|\n",
      "|118| RRR|       NIT|      IIIT|   Google|52900.5|       YES|           300|\n",
      "|118| RRR|       NIT|       IIT|   Google|52900.5|       YES|           240|\n",
      "|118| RRR|       NIT|      IISC|   Google|52900.5|       YES|           250|\n",
      "|118| RRR|       NIT|      JNTU|   Google|52900.5|        NO|           250|\n",
      "|121| UUU|       NIT|      IISC|   Google|59250.2|       YES|           250|\n",
      "|121| UUU|       NIT|       IIT|   Google|59250.2|       YES|           240|\n",
      "|121| UUU|       NIT|       MIT|   Google|59250.2|       YES|           230|\n",
      "|121| UUU|       NIT|      JNTU|   Google|59250.2|        NO|           250|\n",
      "|121| UUU|       NIT|      IIIT|   Google|59250.2|       YES|           300|\n",
      "|104| DDD|       VIT|      JNTU|    Apple|54980.6|        NO|           250|\n",
      "|104| DDD|       VIT|       MIT|    Apple|54980.6|       YES|           230|\n",
      "|104| DDD|       VIT|       IIT|    Apple|54980.6|       YES|           240|\n",
      "|104| DDD|       VIT|      IISC|    Apple|54980.6|       YES|           250|\n",
      "|104| DDD|       VIT|      IIIT|    Apple|54980.6|       YES|           300|\n",
      "|107| GGG|       VIT|      IIIT|   Amazon|60200.7|       YES|           300|\n",
      "|107| GGG|       VIT|       MIT|   Amazon|60200.7|       YES|           230|\n",
      "|107| GGG|       VIT|      IISC|   Amazon|60200.7|       YES|           250|\n",
      "|107| GGG|       VIT|       IIT|   Amazon|60200.7|       YES|           240|\n",
      "|107| GGG|       VIT|      JNTU|   Amazon|60200.7|        NO|           250|\n",
      "|113| MMM|       VIT|      IIIT|   Google|60200.7|       YES|           300|\n",
      "|113| MMM|       VIT|      IISC|   Google|60200.7|       YES|           250|\n",
      "|113| MMM|       VIT|       IIT|   Google|60200.7|       YES|           240|\n",
      "|113| MMM|       VIT|       MIT|   Google|60200.7|       YES|           230|\n",
      "|113| MMM|       VIT|      JNTU|   Google|60200.7|        NO|           250|\n",
      "|119| SSS|       VIT|      IISC|Microsoft|62900.5|       YES|           250|\n",
      "|119| SSS|       VIT|       IIT|Microsoft|62900.5|       YES|           240|\n",
      "|119| SSS|       VIT|       MIT|Microsoft|62900.5|       YES|           230|\n",
      "|119| SSS|       VIT|      JNTU|Microsoft|62900.5|        NO|           250|\n",
      "|119| SSS|       VIT|      IIIT|Microsoft|62900.5|       YES|           300|\n",
      "|123| WWW|       VIT|      IISC|    Apple|59050.5|       YES|           250|\n",
      "|123| WWW|       VIT|       IIT|    Apple|59050.5|       YES|           240|\n",
      "|123| WWW|       VIT|      JNTU|    Apple|59050.5|        NO|           250|\n",
      "|123| WWW|       VIT|       MIT|    Apple|59050.5|       YES|           230|\n",
      "|123| WWW|       VIT|      IIIT|    Apple|59050.5|       YES|           300|\n",
      "+---+----+----------+----------+---------+-------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CROSS JOIN produces a result set which is the number of rows in the first table multiplied by the number of rows in the second table if no WHERE clause is used along with CROSS JOIN.\n",
    "#This kind of result is called as Cartesian Product.\n",
    "\n",
    "print(\"4M5). Example for Cross Join Query\")\n",
    "print(\"\\nCount of Student_Table = \",student_dfps.count())\n",
    "print(\"\\nCount of University_Table = \",university_dfps.count())\n",
    "print(\"\\nCount(Student_Table) X Count(University_Table) = \",student_dfps.count() * university_dfps.count())\n",
    "\n",
    "sql_query=\"\"\"SELECT A.ID, A.Name, A.University, B.University, A.Company, A.Salary, B.PlayGround, B.Total_Students \n",
    "FROM Student_Table A \n",
    "CROSS JOIN University_Table B\n",
    "ORDER BY A.University, ID\"\"\"\n",
    "spark.sql(sql_query).show(500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4N. Union, Union all, Except"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4N2).Union All--> Combine all results from multiple select statements.Duplicates are not Allowed\n",
      "+----------+\n",
      "|University|\n",
      "+----------+\n",
      "|       NIT|\n",
      "|       IIT|\n",
      "|      IIIT|\n",
      "|      IISC|\n",
      "|       VIT|\n",
      "|       MIT|\n",
      "|      JNTU|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Union: Will combine 2 or more results from select statements without duplicates.\n",
    "print(\"4N2).Union All--> Combine all results from multiple select statements.Duplicates are not Allowed\")\n",
    "sql_query=\"\"\"SELECT University FROM Student_Table\n",
    "UNION\n",
    "SELECT University FROM University_Table\n",
    "\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Union all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4N2).Union All--> Combine all results from multiple select statements.Duplicates are awllowed\n",
      "+----------+\n",
      "|University|\n",
      "+----------+\n",
      "|      IISC|\n",
      "|      IIIT|\n",
      "|       NIT|\n",
      "|       VIT|\n",
      "|       IIT|\n",
      "|      IIIT|\n",
      "|       VIT|\n",
      "|       NIT|\n",
      "|      IIIT|\n",
      "|       NIT|\n",
      "|      IISC|\n",
      "|       NIT|\n",
      "|       VIT|\n",
      "|      IIIT|\n",
      "|      IISC|\n",
      "|       IIT|\n",
      "|      IISC|\n",
      "|       NIT|\n",
      "|       VIT|\n",
      "|      IIIT|\n",
      "|       NIT|\n",
      "|      IISC|\n",
      "|       VIT|\n",
      "|       IIT|\n",
      "|      IISC|\n",
      "|      IIIT|\n",
      "|       MIT|\n",
      "|       IIT|\n",
      "|      JNTU|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Union: Will combine 2 or more results from select statements without duplicates.\n",
    "print(\"4N2).Union All--> Combine all results from multiple select statements.Duplicates are awllowed\")\n",
    "sql_query=\"\"\"SELECT University FROM Student_Table\n",
    "UNION ALL\n",
    "SELECT University FROM University_Table\n",
    "\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Except"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4N3).Except: acts like Minus operator\n",
      "+----------+\n",
      "|University|\n",
      "+----------+\n",
      "|       NIT|\n",
      "|       VIT|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Except: acts like Minus operator, it will print extra records in first results than second results\n",
    "print(\"4N3).Except: acts like Minus operator\")\n",
    "sql_query=\"\"\"SELECT University FROM Student_Table\n",
    "EXCEPT\n",
    "SELECT University FROM University_Table\n",
    "\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4O. Window functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print sample data from Student_Table\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "| ID|Name|Gender|       DOB|Location|University| Salary|  Company|          Email|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "|101| AAA|     M|1994-10-10|Banglore|      IISC|55000.5|Microsoft|  AAA@gmail.com|\n",
      "|102| BBB|     F|1995-09-20|     HYD|      IIIT|76000.2|   Amazon|BBB@hotmail.com|\n",
      "|103| CCC|     M|1992-12-31| Chennai|       NIT|49200.5|   Google|  CCC@gmail.com|\n",
      "|104| DDD|     F|1990-11-22|  Mumbai|       VIT|54980.6|    Apple|DDD@hotmail.com|\n",
      "|105| EEE|     M|1993-05-19| Chennai|       IIT|60200.7|Microsoft|  EEE@gmail.com|\n",
      "|106| FFF|     M|1994-07-23|     HYD|      IIIT|63100.8|Microsoft|  FFF@gmail.com|\n",
      "|107| GGG|     F|1994-10-10|  Mumbai|       VIT|60200.7|   Amazon|GGG@hotmail.com|\n",
      "|108| HHH|     M|1990-10-10|Banglore|       NIT|89200.7|    Apple|  HHH@gmail.com|\n",
      "|109| III|     F|1994-12-21|     HYD|      IIIT|66980.8|   Google|  III@gmail.com|\n",
      "|110| JJJ|     M|1990-11-22| Chennai|       NIT|59250.2|   Amazon|JJJ@hotmail.com|\n",
      "|111| KKK|     M|1994-10-10|Banglore|      IISC|76300.9|Microsoft|  KKK@gmail.com|\n",
      "|112| LLL|     F|1995-09-20|  Mumbai|       NIT|67900.8|    Apple|  LLL@gmail.com|\n",
      "|113| MMM|     F|1994-10-15|     NaN|       VIT|60200.7|   Google|MMM@hotmail.com|\n",
      "|114| NNN|     F|1990-11-29|Banglore|      IIIT|59200.5|   Amazon|  NNN@gmail.com|\n",
      "|115| OOO|     M|1995-09-20|Banglore|      IISC|57120.5|   Google|  OOO@gmail.com|\n",
      "|116| PPP|     F|1994-10-28| Chennai|       IIT|59050.5|    Apple|  PPP@gmail.com|\n",
      "|117| QQQ|     M|1991-02-10|Banglore|      IISC|60200.7|Microsoft|QQQ@hotmail.com|\n",
      "|118| RRR|     F|1993-11-10|  Mumbai|       NIT|52900.5|   Google|  RRR@gmail.com|\n",
      "|119| SSS|     M|1992-10-25|     NaN|       VIT|62900.5|Microsoft|  SSS@gmail.com|\n",
      "|120| TTT|     M|1995-09-29| Chennai|      IIIT|57230.5|    Apple|TTT@hotmail.com|\n",
      "|121| UUU|     F|1990-11-13| Chennai|       NIT|59250.2|   Google|  UUU@gmail.com|\n",
      "|122| VVV|     M|1993-08-19|Banglore|      IISC|57120.5|Microsoft|  VVV@gmail.com|\n",
      "|123| WWW|     F|1994-09-14|  Mumbai|       VIT|59050.5|    Apple|WWW@hotmail.com|\n",
      "|124| XXX|     M|1991-12-19|     HYD|       IIT|60200.7|Microsoft|  XXX@gmail.com|\n",
      "+---+----+------+----------+--------+----------+-------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(\"Print sample data from Student_Table\")\n",
    "sql_query=\"\"\"SELECT * FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Row_Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4O1A).Give Row_number based on Company in each Location\n",
      "+---+----+------+-------+--------+---------+--------------------------+\n",
      "| ID|Name|Gender| Salary|Location|  Company|RowNumber_Company_Location|\n",
      "+---+----+------+-------+--------+---------+--------------------------+\n",
      "|110| JJJ|     M|59250.2| Chennai|   Amazon|                         1|\n",
      "|116| PPP|     F|59050.5| Chennai|    Apple|                         2|\n",
      "|120| TTT|     M|57230.5| Chennai|    Apple|                         3|\n",
      "|103| CCC|     M|49200.5| Chennai|   Google|                         4|\n",
      "|121| UUU|     F|59250.2| Chennai|   Google|                         5|\n",
      "|105| EEE|     M|60200.7| Chennai|Microsoft|                         6|\n",
      "|107| GGG|     F|60200.7|  Mumbai|   Amazon|                         1|\n",
      "|104| DDD|     F|54980.6|  Mumbai|    Apple|                         2|\n",
      "|112| LLL|     F|67900.8|  Mumbai|    Apple|                         3|\n",
      "|123| WWW|     F|59050.5|  Mumbai|    Apple|                         4|\n",
      "|118| RRR|     F|52900.5|  Mumbai|   Google|                         5|\n",
      "|113| MMM|     F|60200.7|     NaN|   Google|                         1|\n",
      "|119| SSS|     M|62900.5|     NaN|Microsoft|                         2|\n",
      "|102| BBB|     F|76000.2|     HYD|   Amazon|                         1|\n",
      "|109| III|     F|66980.8|     HYD|   Google|                         2|\n",
      "|106| FFF|     M|63100.8|     HYD|Microsoft|                         3|\n",
      "|124| XXX|     M|60200.7|     HYD|Microsoft|                         4|\n",
      "|114| NNN|     F|59200.5|Banglore|   Amazon|                         1|\n",
      "|108| HHH|     M|89200.7|Banglore|    Apple|                         2|\n",
      "|115| OOO|     M|57120.5|Banglore|   Google|                         3|\n",
      "|101| AAA|     M|55000.5|Banglore|Microsoft|                         4|\n",
      "|111| KKK|     M|76300.9|Banglore|Microsoft|                         5|\n",
      "|117| QQQ|     M|60200.7|Banglore|Microsoft|                         6|\n",
      "|122| VVV|     M|57120.5|Banglore|Microsoft|                         7|\n",
      "+---+----+------+-------+--------+---------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Row_number: Will assign sequential interger to all rows within the partition of result set.\n",
    "\n",
    "\n",
    "print(\"4O1A).Give Row_number based on Company in each Location\")\n",
    "\n",
    "sql_query=\"\"\"SELECT ID, Name, Gender, Salary, Location, Company,\n",
    "ROW_NUMBER() OVER(PARTITION BY Location ORDER BY Company) AS RowNumber_Company_Location\n",
    "FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4O2A).Give Ranking based on Salary in each Company\n",
      "+---+----+------+--------+---------+-------+-------------------+\n",
      "| ID|Name|Gender|Location|  Company| Salary|Rank_Salary_Company|\n",
      "+---+----+------+--------+---------+-------+-------------------+\n",
      "|109| III|     F|     HYD|   Google|66980.8|                  1|\n",
      "|113| MMM|     F|     NaN|   Google|60200.7|                  2|\n",
      "|121| UUU|     F| Chennai|   Google|59250.2|                  3|\n",
      "|115| OOO|     M|Banglore|   Google|57120.5|                  4|\n",
      "|118| RRR|     F|  Mumbai|   Google|52900.5|                  5|\n",
      "|103| CCC|     M| Chennai|   Google|49200.5|                  6|\n",
      "|111| KKK|     M|Banglore|Microsoft|76300.9|                  1|\n",
      "|106| FFF|     M|     HYD|Microsoft|63100.8|                  2|\n",
      "|119| SSS|     M|     NaN|Microsoft|62900.5|                  3|\n",
      "|105| EEE|     M| Chennai|Microsoft|60200.7|                  4|\n",
      "|117| QQQ|     M|Banglore|Microsoft|60200.7|                  4|\n",
      "|124| XXX|     M|     HYD|Microsoft|60200.7|                  4|\n",
      "|122| VVV|     M|Banglore|Microsoft|57120.5|                  7|\n",
      "|101| AAA|     M|Banglore|Microsoft|55000.5|                  8|\n",
      "|108| HHH|     M|Banglore|    Apple|89200.7|                  1|\n",
      "|112| LLL|     F|  Mumbai|    Apple|67900.8|                  2|\n",
      "|116| PPP|     F| Chennai|    Apple|59050.5|                  3|\n",
      "|123| WWW|     F|  Mumbai|    Apple|59050.5|                  3|\n",
      "|120| TTT|     M| Chennai|    Apple|57230.5|                  5|\n",
      "|104| DDD|     F|  Mumbai|    Apple|54980.6|                  6|\n",
      "|102| BBB|     F|     HYD|   Amazon|76000.2|                  1|\n",
      "|107| GGG|     F|  Mumbai|   Amazon|60200.7|                  2|\n",
      "|110| JJJ|     M| Chennai|   Amazon|59250.2|                  3|\n",
      "|114| NNN|     F|Banglore|   Amazon|59200.5|                  4|\n",
      "+---+----+------+--------+---------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RanK: Will assign rank to each record in given partition or Group. \n",
    "#If have same values will assign same rank, but skips next rank for upcoming values.\n",
    "\n",
    "print(\"4O2A).Give Ranking based on Salary in each Company\")\n",
    "\n",
    "sql_query=\"\"\"SELECT ID, Name, Gender, Location, Company, Salary,\n",
    "RANK() OVER(PARTITION BY Company ORDER BY Salary DESC) AS Rank_Salary_Company\n",
    "FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4O2B).Give Ranking based on Salary in each Company\n",
      "+---+----+------+-------+--------+---------+---------------------+\n",
      "| ID|Name|Gender| Salary|Location|  Company|Rank_Company_Location|\n",
      "+---+----+------+-------+--------+---------+---------------------+\n",
      "|110| JJJ|     M|59250.2| Chennai|   Amazon|                    1|\n",
      "|116| PPP|     F|59050.5| Chennai|    Apple|                    2|\n",
      "|120| TTT|     M|57230.5| Chennai|    Apple|                    2|\n",
      "|103| CCC|     M|49200.5| Chennai|   Google|                    4|\n",
      "|121| UUU|     F|59250.2| Chennai|   Google|                    4|\n",
      "|105| EEE|     M|60200.7| Chennai|Microsoft|                    6|\n",
      "|107| GGG|     F|60200.7|  Mumbai|   Amazon|                    1|\n",
      "|104| DDD|     F|54980.6|  Mumbai|    Apple|                    2|\n",
      "|112| LLL|     F|67900.8|  Mumbai|    Apple|                    2|\n",
      "|123| WWW|     F|59050.5|  Mumbai|    Apple|                    2|\n",
      "|118| RRR|     F|52900.5|  Mumbai|   Google|                    5|\n",
      "|113| MMM|     F|60200.7|     NaN|   Google|                    1|\n",
      "|119| SSS|     M|62900.5|     NaN|Microsoft|                    2|\n",
      "|102| BBB|     F|76000.2|     HYD|   Amazon|                    1|\n",
      "|109| III|     F|66980.8|     HYD|   Google|                    2|\n",
      "|106| FFF|     M|63100.8|     HYD|Microsoft|                    3|\n",
      "|124| XXX|     M|60200.7|     HYD|Microsoft|                    3|\n",
      "|114| NNN|     F|59200.5|Banglore|   Amazon|                    1|\n",
      "|108| HHH|     M|89200.7|Banglore|    Apple|                    2|\n",
      "|115| OOO|     M|57120.5|Banglore|   Google|                    3|\n",
      "|101| AAA|     M|55000.5|Banglore|Microsoft|                    4|\n",
      "|111| KKK|     M|76300.9|Banglore|Microsoft|                    4|\n",
      "|117| QQQ|     M|60200.7|Banglore|Microsoft|                    4|\n",
      "|122| VVV|     M|57120.5|Banglore|Microsoft|                    4|\n",
      "+---+----+------+-------+--------+---------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RanK: Will assign rank to each record in given partition or Group. \n",
    "#If have same values will assign same rank, but skips next rank for upcoming values.\n",
    "\n",
    "print(\"4O2B).Give Ranking based on Salary in each Company\")\n",
    "\n",
    "sql_query=\"\"\"SELECT ID, Name, Gender,  Salary, Location, Company,\n",
    "RANK() OVER(PARTITION BY Location ORDER BY Company) AS Rank_Company_Location\n",
    "FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dense Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4O3).Give Ranking based on Salary in each Company\n",
      "+---+----+------+-------+--------+---------+---------------------+\n",
      "| ID|Name|Gender| Salary|Location|  Company|Rank_Company_Location|\n",
      "+---+----+------+-------+--------+---------+---------------------+\n",
      "|110| JJJ|     M|59250.2| Chennai|   Amazon|                    1|\n",
      "|116| PPP|     F|59050.5| Chennai|    Apple|                    2|\n",
      "|120| TTT|     M|57230.5| Chennai|    Apple|                    2|\n",
      "|103| CCC|     M|49200.5| Chennai|   Google|                    3|\n",
      "|121| UUU|     F|59250.2| Chennai|   Google|                    3|\n",
      "|105| EEE|     M|60200.7| Chennai|Microsoft|                    4|\n",
      "|107| GGG|     F|60200.7|  Mumbai|   Amazon|                    1|\n",
      "|104| DDD|     F|54980.6|  Mumbai|    Apple|                    2|\n",
      "|112| LLL|     F|67900.8|  Mumbai|    Apple|                    2|\n",
      "|123| WWW|     F|59050.5|  Mumbai|    Apple|                    2|\n",
      "|118| RRR|     F|52900.5|  Mumbai|   Google|                    3|\n",
      "|113| MMM|     F|60200.7|     NaN|   Google|                    1|\n",
      "|119| SSS|     M|62900.5|     NaN|Microsoft|                    2|\n",
      "|102| BBB|     F|76000.2|     HYD|   Amazon|                    1|\n",
      "|109| III|     F|66980.8|     HYD|   Google|                    2|\n",
      "|106| FFF|     M|63100.8|     HYD|Microsoft|                    3|\n",
      "|124| XXX|     M|60200.7|     HYD|Microsoft|                    3|\n",
      "|114| NNN|     F|59200.5|Banglore|   Amazon|                    1|\n",
      "|108| HHH|     M|89200.7|Banglore|    Apple|                    2|\n",
      "|115| OOO|     M|57120.5|Banglore|   Google|                    3|\n",
      "|101| AAA|     M|55000.5|Banglore|Microsoft|                    4|\n",
      "|111| KKK|     M|76300.9|Banglore|Microsoft|                    4|\n",
      "|117| QQQ|     M|60200.7|Banglore|Microsoft|                    4|\n",
      "|122| VVV|     M|57120.5|Banglore|Microsoft|                    4|\n",
      "+---+----+------+-------+--------+---------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DENSE_RanK: Will assign rank to each record in given partition or Group. \n",
    "#If have same values will assign same rank, but it won't skips next rank for upcoming values.\n",
    "\n",
    "print(\"4O3).Give Ranking based on Salary in each Company\")\n",
    "\n",
    "sql_query=\"\"\"SELECT ID, Name, Gender, Salary, Location, Company, \n",
    "DENSE_RANK() OVER(PARTITION BY Location ORDER BY Company) AS Rank_Company_Location\n",
    "FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NTile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4O4).Convert ID into NTILE(5) Buckets\n",
      "+---+--------+-----------+\n",
      "| ID|Location|NTILE_on_ID|\n",
      "+---+--------+-----------+\n",
      "|101|Banglore|          1|\n",
      "|102|     HYD|          1|\n",
      "|103| Chennai|          1|\n",
      "|104|  Mumbai|          1|\n",
      "|105| Chennai|          1|\n",
      "|106|     HYD|          2|\n",
      "|107|  Mumbai|          2|\n",
      "|108|Banglore|          2|\n",
      "|109|     HYD|          2|\n",
      "|110| Chennai|          2|\n",
      "|111|Banglore|          3|\n",
      "|112|  Mumbai|          3|\n",
      "|113|     NaN|          3|\n",
      "|114|Banglore|          3|\n",
      "|115|Banglore|          3|\n",
      "|116| Chennai|          4|\n",
      "|117|Banglore|          4|\n",
      "|118|  Mumbai|          4|\n",
      "|119|     NaN|          4|\n",
      "|120| Chennai|          4|\n",
      "|121| Chennai|          5|\n",
      "|122|Banglore|          5|\n",
      "|123|  Mumbai|          5|\n",
      "|124|     HYD|          5|\n",
      "+---+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NTile: will distributes rows of an ordered partition into a specified number of approximately equal groups, or buckets.\n",
    "\n",
    "print(\"4O4).Convert ID into NTILE(5) Buckets\")\n",
    "\n",
    "sql_query=\"\"\"SELECT ID, Location,\n",
    "NTILE(5) OVER(ORDER BY ID) AS NTILE_on_ID\n",
    "FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4O5).Lead function example\n",
      "+---+--------+---------+-------+-------------+\n",
      "| ID|Location|  Company| Salary|Lead_2_Salary|\n",
      "+---+--------+---------+-------+-------------+\n",
      "|101|Banglore|Microsoft|55000.5|      49200.5|\n",
      "|102|     HYD|   Amazon|76000.2|      54980.6|\n",
      "|103| Chennai|   Google|49200.5|      60200.7|\n",
      "|104|  Mumbai|    Apple|54980.6|      63100.8|\n",
      "|105| Chennai|Microsoft|60200.7|      60200.7|\n",
      "|106|     HYD|Microsoft|63100.8|      89200.7|\n",
      "|107|  Mumbai|   Amazon|60200.7|      66980.8|\n",
      "|108|Banglore|    Apple|89200.7|      59250.2|\n",
      "|109|     HYD|   Google|66980.8|      76300.9|\n",
      "|110| Chennai|   Amazon|59250.2|      67900.8|\n",
      "|111|Banglore|Microsoft|76300.9|      60200.7|\n",
      "|112|  Mumbai|    Apple|67900.8|      59200.5|\n",
      "|113|     NaN|   Google|60200.7|      57120.5|\n",
      "|114|Banglore|   Amazon|59200.5|      59050.5|\n",
      "|115|Banglore|   Google|57120.5|      60200.7|\n",
      "|116| Chennai|    Apple|59050.5|      52900.5|\n",
      "|117|Banglore|Microsoft|60200.7|      62900.5|\n",
      "|118|  Mumbai|   Google|52900.5|      57230.5|\n",
      "|119|     NaN|Microsoft|62900.5|      59250.2|\n",
      "|120| Chennai|    Apple|57230.5|      57120.5|\n",
      "|121| Chennai|   Google|59250.2|      59050.5|\n",
      "|122|Banglore|Microsoft|57120.5|      60200.7|\n",
      "|123|  Mumbai|    Apple|59050.5|         null|\n",
      "|124|     HYD|Microsoft|60200.7|         null|\n",
      "+---+--------+---------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lead: will provide the value leading to given offset tothe current row.\n",
    "#Parameters--> column: we want this lead, offset: howmany rows should lead\n",
    "\n",
    "print(\"4O5).Lead function example\")\n",
    "\n",
    "sql_query=\"\"\"SELECT ID, Location, Company, Salary, \n",
    "LEAD(Salary,2) OVER(ORDER BY ID) AS Lead_2_Salary\n",
    "FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4O6).Lead function example\n",
      "+---+--------+---------+-------+------------+\n",
      "| ID|Location|  Company| Salary|Lag_3_Salary|\n",
      "+---+--------+---------+-------+------------+\n",
      "|101|Banglore|Microsoft|55000.5|        null|\n",
      "|102|     HYD|   Amazon|76000.2|        null|\n",
      "|103| Chennai|   Google|49200.5|        null|\n",
      "|104|  Mumbai|    Apple|54980.6|     55000.5|\n",
      "|105| Chennai|Microsoft|60200.7|     76000.2|\n",
      "|106|     HYD|Microsoft|63100.8|     49200.5|\n",
      "|107|  Mumbai|   Amazon|60200.7|     54980.6|\n",
      "|108|Banglore|    Apple|89200.7|     60200.7|\n",
      "|109|     HYD|   Google|66980.8|     63100.8|\n",
      "|110| Chennai|   Amazon|59250.2|     60200.7|\n",
      "|111|Banglore|Microsoft|76300.9|     89200.7|\n",
      "|112|  Mumbai|    Apple|67900.8|     66980.8|\n",
      "|113|     NaN|   Google|60200.7|     59250.2|\n",
      "|114|Banglore|   Amazon|59200.5|     76300.9|\n",
      "|115|Banglore|   Google|57120.5|     67900.8|\n",
      "|116| Chennai|    Apple|59050.5|     60200.7|\n",
      "|117|Banglore|Microsoft|60200.7|     59200.5|\n",
      "|118|  Mumbai|   Google|52900.5|     57120.5|\n",
      "|119|     NaN|Microsoft|62900.5|     59050.5|\n",
      "|120| Chennai|    Apple|57230.5|     60200.7|\n",
      "|121| Chennai|   Google|59250.2|     52900.5|\n",
      "|122|Banglore|Microsoft|57120.5|     62900.5|\n",
      "|123|  Mumbai|    Apple|59050.5|     57230.5|\n",
      "|124|     HYD|Microsoft|60200.7|     59250.2|\n",
      "+---+--------+---------+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LAG: will provide the value leading to given offset tothe current row.\n",
    "#Parameters--> column: we want this lead, offset: howmany rows should lead\n",
    "\n",
    "print(\"4O6).Lead function example\")\n",
    "\n",
    "sql_query=\"\"\"SELECT ID, Location, Company, Salary, \n",
    "LAG(Salary,3) OVER(ORDER BY ID) AS Lag_3_Salary\n",
    "FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running Aggregated functions(SUM,AVG,MIN,MAX,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4O7).Running Total example on Salary Column partition by Company.\n",
      "+---+--------+---------+-------+-------------+\n",
      "| ID|Location|  Company| Salary|Running_Total|\n",
      "+---+--------+---------+-------+-------------+\n",
      "|103| Chennai|   Google|49200.5|      49201.0|\n",
      "|118|  Mumbai|   Google|52900.5|     102102.0|\n",
      "|115|Banglore|   Google|57120.5|     159223.0|\n",
      "|121| Chennai|   Google|59250.2|     218473.0|\n",
      "|113|     NaN|   Google|60200.7|     278674.0|\n",
      "|109|     HYD|   Google|66980.8|     345655.0|\n",
      "|101|Banglore|Microsoft|55000.5|      55001.0|\n",
      "|122|Banglore|Microsoft|57120.5|     112122.0|\n",
      "|105| Chennai|Microsoft|60200.7|     292725.0|\n",
      "|117|Banglore|Microsoft|60200.7|     292725.0|\n",
      "|124|     HYD|Microsoft|60200.7|     292725.0|\n",
      "|119|     NaN|Microsoft|62900.5|     355626.0|\n",
      "|106|     HYD|Microsoft|63100.8|     418727.0|\n",
      "|111|Banglore|Microsoft|76300.9|     495028.0|\n",
      "|104|  Mumbai|    Apple|54980.6|      54981.0|\n",
      "|120| Chennai|    Apple|57230.5|     112212.0|\n",
      "|116| Chennai|    Apple|59050.5|     230314.0|\n",
      "|123|  Mumbai|    Apple|59050.5|     230314.0|\n",
      "|112|  Mumbai|    Apple|67900.8|     298215.0|\n",
      "|108|Banglore|    Apple|89200.7|     387416.0|\n",
      "|114|Banglore|   Amazon|59200.5|      59201.0|\n",
      "|110| Chennai|   Amazon|59250.2|     118451.0|\n",
      "|107|  Mumbai|   Amazon|60200.7|     178652.0|\n",
      "|102|     HYD|   Amazon|76000.2|     254652.0|\n",
      "+---+--------+---------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Running SUM--> will gives the sum of given column till current row. It will calculate for every record in given partition.\n",
    "#It is different than normal SUM() function used with group by clause, as it will only single value.\n",
    "#We can use any Aggregated functions in place of SUM(<Column Name>)\n",
    "\n",
    "print(\"4O7).Running Total example on Salary Column partition by Company.\")\n",
    "\n",
    "sql_query=\"\"\"SELECT ID, Location, Company, Salary, \n",
    "SUM(ROUND(SALARY)) OVER (PARTITION BY COMPANY ORDER BY SALARY) AS Running_Total\n",
    "FROM Student_Table\"\"\"\n",
    "spark.sql(sql_query).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4P. ROLLUP , CUBE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "1)These two functions are used to calculate grand total. and these two functions are applied with group by clause.\n",
    "2)ROLLUP generates a result set that shows aggregates for a hierarchy of values in the selected columns.\n",
    "3)CUBE generates a result set that shows aggregates for all combinations of values in the selected columns\n",
    "\n",
    "Better to see the below examples.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RollUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4P1).RollUp example.\n",
      "+---------+----------+--------+-----------+\n",
      "|     YEAR|     Month|     Day|sum(Salary)|\n",
      "+---------+----------+--------+-----------+\n",
      "|     2000| 1.January|      21|         10|\n",
      "|     2000| 1.January|      22|         10|\n",
      "|     2000| 1.January|      23|         10|\n",
      "|     2000| 1.January|All Days|         30|\n",
      "|     2000|2.February|      21|         10|\n",
      "|     2000|2.February|      22|         10|\n",
      "|     2000|2.February|      23|         10|\n",
      "|     2000|2.February|All Days|         30|\n",
      "|     2000|All Months|All Days|         60|\n",
      "|     2001| 1.January|      21|         10|\n",
      "|     2001| 1.January|      22|         10|\n",
      "|     2001| 1.January|      23|         10|\n",
      "|     2001| 1.January|All Days|         30|\n",
      "|     2001|2.February|      21|         10|\n",
      "|     2001|2.February|      22|         10|\n",
      "|     2001|2.February|      23|         10|\n",
      "|     2001|2.February|All Days|         30|\n",
      "|     2001|All Months|All Days|         60|\n",
      "|All Years|All Months|All Days|        120|\n",
      "+---------+----------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"#ROLLUP (YEAR, MONTH, DAY) will give below output:\n",
    "\n",
    "YEAR, MONTH, DAY\n",
    "YEAR, MONTH\n",
    "YEAR\n",
    "()\n",
    "\"\"\"\n",
    "\n",
    "print(\"4P1).RollUp example.\")\n",
    "\n",
    "sql_query=\"\"\"SELECT \n",
    "COALESCE(Year,\"All Years\") AS YEAR, \n",
    "COALESCE(Month,\"All Months\") AS Month, \n",
    "COALESCE(Day,\"All Days\") AS Day, \n",
    "SUM(Salary)\n",
    "FROM Year_Month_Day_Table\n",
    "GROUP BY ROLLUP (Year, Month, Day)\n",
    "ORDER BY Year, Month, Day\n",
    "\"\"\"\n",
    "spark.sql(sql_query).show(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CUBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4P2).CUBE example.\n",
      "+---------+----------+--------+-----------+\n",
      "|     YEAR|     Month|     Day|sum(Salary)|\n",
      "+---------+----------+--------+-----------+\n",
      "|     2000| 1.January|      21|         10|\n",
      "|     2000| 1.January|      22|         10|\n",
      "|     2000| 1.January|      23|         10|\n",
      "|     2000| 1.January|All Days|         30|\n",
      "|     2000|2.February|      21|         10|\n",
      "|     2000|2.February|      22|         10|\n",
      "|     2000|2.February|      23|         10|\n",
      "|     2000|2.February|All Days|         30|\n",
      "|     2000|All Months|      21|         20|\n",
      "|     2000|All Months|      22|         20|\n",
      "|     2000|All Months|      23|         20|\n",
      "|     2000|All Months|All Days|         60|\n",
      "|     2001| 1.January|      21|         10|\n",
      "|     2001| 1.January|      22|         10|\n",
      "|     2001| 1.January|      23|         10|\n",
      "|     2001| 1.January|All Days|         30|\n",
      "|     2001|2.February|      21|         10|\n",
      "|     2001|2.February|      22|         10|\n",
      "|     2001|2.February|      23|         10|\n",
      "|     2001|2.February|All Days|         30|\n",
      "|     2001|All Months|      21|         20|\n",
      "|     2001|All Months|      22|         20|\n",
      "|     2001|All Months|      23|         20|\n",
      "|     2001|All Months|All Days|         60|\n",
      "|All Years| 1.January|      21|         20|\n",
      "|All Years| 1.January|      22|         20|\n",
      "|All Years| 1.January|      23|         20|\n",
      "|All Years| 1.January|All Days|         60|\n",
      "|All Years|2.February|      21|         20|\n",
      "|All Years|2.February|      22|         20|\n",
      "|All Years|2.February|      23|         20|\n",
      "|All Years|2.February|All Days|         60|\n",
      "|All Years|All Months|      21|         40|\n",
      "|All Years|All Months|      22|         40|\n",
      "|All Years|All Months|      23|         40|\n",
      "|All Years|All Months|All Days|        120|\n",
      "+---------+----------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"#CUBE (YEAR, MONTH, DAY) will give below output:\n",
    "\n",
    "YEAR, MONTH, DAY\n",
    "YEAR, MONTH\n",
    "YEAR, DAY\n",
    "YEAR\n",
    "MONTH, DAY\n",
    "MONTH\n",
    "DAY\n",
    "()\n",
    "\"\"\"\n",
    "print(\"4P2).CUBE example.\")\n",
    "\n",
    "sql_query=\"\"\"SELECT \n",
    "COALESCE(Year,\"All Years\") AS YEAR, \n",
    "COALESCE(Month,\"All Months\") AS Month, \n",
    "COALESCE(Day,\"All Days\") AS Day, \n",
    "SUM(Salary)\n",
    "FROM Year_Month_Day_Table\n",
    "GROUP BY CUBE (Year, Month, Day)\n",
    "ORDER BY Year, Month, Day\n",
    "\"\"\"\n",
    "spark.sql(sql_query).show(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop SPARK Engine 🚦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop the Spark Engine\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ruff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python dict\n",
    "dict1_Z = {\"Name\": [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\"],\\\n",
    "         \"Weight\":[70,61,83,60,92,69,84,71,77],\\\n",
    "         \"Address\":[\"HYD\",\"Banglore\",\"Chennai\",\"Mumbai\",\"Banglore\",\"Mumbai\",\"Chennai\",\"Banglore\",\"HYD\"],\\\n",
    "         \"DOB\":[\"15-01-1990\", \"19-01-1996\", \"28-02-1999\", \"13-06-1989\", \"15-11-2000\", \"10-12-1995\", \"25-11-1998\", \"15-09-1994\", \"15-01-1996\"],\\\n",
    "         \"Batch\":[2016, 2017, 2018, 2016, 2016, 2017, 2016, 2018, 2017],\\\n",
    "         \"Salary\":[51000.00, 46500.50, 52000.00, 51000.00, 52000.00, 75000.60, 64000.50, 52000.00, 46500.50]         \n",
    "        }\n",
    "\n",
    "#create pandas df\n",
    "dfpd_z = pd.DataFrame(dict1_Z)\n",
    "dfpd_z_dtype = {\"Name\":'str', \"Weight\":'int64', \"Address\":'str', \"DOB\":'datetime64', \"Batch\":'int64', \"Salary\":'float64' }\n",
    "dfpd_z = dfpd_z.astype(dfpd_z_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schema for spark dataframe with Structtype, fields\n",
    "schema_z = StructType([\\\n",
    "                     StructField(\"Name\", StringType(), True),\\\n",
    "                     StructField(\"Weight\", IntegerType(), True),\\\n",
    "                     StructField(\"Address\", StringType(), True),\\\n",
    "                     StructField(\"DOB\", DateType(), True),\\\n",
    "                     StructField(\"Batch\", IntegerType(), True),\\\n",
    "                     StructField(\"Salary\", DoubleType(), True)])\n",
    "\n",
    "#create spark DF by passing pandas df with above schema\n",
    "dfps_z = spark.createDataFrame(dfpd_z, schema_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+--------+----------+-----+-------+\n",
      "|Name|Weight| Address|       DOB|Batch| Salary|\n",
      "+----+------+--------+----------+-----+-------+\n",
      "|   A|    70|     HYD|1990-01-15| 2016|51000.0|\n",
      "|   B|    61|Banglore|1996-01-19| 2017|46500.5|\n",
      "|   C|    83| Chennai|1999-02-28| 2018|52000.0|\n",
      "|   D|    60|  Mumbai|1989-06-13| 2016|51000.0|\n",
      "|   E|    92|Banglore|2000-11-15| 2016|52000.0|\n",
      "|   F|    69|  Mumbai|1995-10-12| 2017|75000.6|\n",
      "|   G|    84| Chennai|1998-11-25| 2016|64000.5|\n",
      "|   H|    71|Banglore|1994-09-15| 2018|52000.0|\n",
      "|   I|    77|     HYD|1996-01-15| 2017|46500.5|\n",
      "+----+------+--------+----------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfps_z.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
